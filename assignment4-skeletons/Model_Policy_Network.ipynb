{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model-Based RL\n",
    "In this exercise you will implement a policy and model network which work in tandem to solve the CartPole reinforcement learning problem."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What is a model and why would we want to use one? In this case, a model is going to be a neural network that attempts to learn the dynamics of the real environment. For example, in the CartPole we would like a model to be able to predict the next position of the Cart given the previous position and an action. By learning an accurate model, we can train our agent using the model rather than requiring to use the real environment every time. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How are we going to accomplish this in Tensorflow? We are going to be using a neural network that will learn the transition dynamics between a previous observation and action, and the expected new observation, reward, and done state. Our training procedure will involve switching between training our model using the real environment, and training our agentâ€™s policy using the model environment. By using this approach we will be able to learn a policy that allows our agent to solve the CartPole task without actually ever training the policy on the real environment! "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading libraries and starting CartPole environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "import numpy as np\n",
    "try:\n",
    "    import cPickle as pickle\n",
    "except:\n",
    "    import pickle\n",
    "import tensorflow as tf\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "if sys.version_info.major > 2:\n",
    "    xrange = range\n",
    "del sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2017-07-21 10:48:33,259] Making new env: CartPole-v0\n"
     ]
    }
   ],
   "source": [
    "import gym\n",
    "env = gym.make('CartPole-v0')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setting Hyper-parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# hyperparameters\n",
    "H = 8 # number of hidden layer neurons\n",
    "learning_rate = 1e-2\n",
    "gamma = 0.99 # discount factor for reward\n",
    "decay_rate = 0.99 # decay factor for RMSProp leaky sum of grad^2\n",
    "resume = False # resume from previous checkpoint?\n",
    "\n",
    "model_bs = 3 # Batch size when learning from model\n",
    "real_bs = 3 # Batch size when learning from real environment\n",
    "\n",
    "# model initialization\n",
    "D = 4 # input dimensionality"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Policy Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'loss' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-6-7ca6bca5c028>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     27\u001b[0m \u001b[1;31m################################################################################\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     28\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 29\u001b[1;33m \u001b[0mnewGrads\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgradients\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mtvars\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     30\u001b[0m \u001b[0mupdateGrads\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0madam\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply_gradients\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatchGrad\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mtvars\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'loss' is not defined"
     ]
    }
   ],
   "source": [
    "tf.reset_default_graph()\n",
    "observations = tf.placeholder(tf.float32, [None,4] , name=\"input_x\")\n",
    "W1 = tf.get_variable(\"W1\", shape=[4, H],\n",
    "           initializer=tf.contrib.layers.xavier_initializer())\n",
    "layer1 = tf.nn.relu(tf.matmul(observations,W1))\n",
    "W2 = tf.get_variable(\"W2\", shape=[H, 1],\n",
    "           initializer=tf.contrib.layers.xavier_initializer())\n",
    "score = tf.matmul(layer1,W2)\n",
    "probability = tf.nn.sigmoid(score)\n",
    "\n",
    "tvars = tf.trainable_variables()\n",
    "input_y = tf.placeholder(tf.float32,[None,1], name=\"input_y\")\n",
    "advantages = tf.placeholder(tf.float32,name=\"reward_signal\")\n",
    "adam = tf.train.AdamOptimizer(learning_rate=learning_rate)\n",
    "W1Grad = tf.placeholder(tf.float32,name=\"batch_grad1\")\n",
    "W2Grad = tf.placeholder(tf.float32,name=\"batch_grad2\")\n",
    "batchGrad = [W1Grad,W2Grad]\n",
    "\n",
    "################################################################################\n",
    "# TODO: Implement the loss function.                                           #\n",
    "# This sends the weights in the direction of making actions that gave good     #\n",
    "# advantage (reward overtime) more likely, and actions that didn't less likely.#\n",
    "################################################################################\n",
    "pass\n",
    "################################################################################\n",
    "#                                 END OF YOUR CODE                             #\n",
    "################################################################################\n",
    "\n",
    "newGrads = tf.gradients(loss,tvars)\n",
    "updateGrads = adam.apply_gradients(zip(batchGrad,tvars))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Network\n",
    "Here we implement a multi-layer neural network that predicts the next observation, reward, and done state from a current state and action."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "mH = 256 # model layer size\n",
    "\n",
    "input_data = tf.placeholder(tf.float32, [None, 5])\n",
    "with tf.variable_scope('rnnlm'):\n",
    "    softmax_w = tf.get_variable(\"softmax_w\", [mH, 50])\n",
    "    softmax_b = tf.get_variable(\"softmax_b\", [50])\n",
    "\n",
    "previous_state = tf.placeholder(tf.float32, [None,5] , name=\"previous_state\")\n",
    "W1M = tf.get_variable(\"W1M\", shape=[5, mH],\n",
    "           initializer=tf.contrib.layers.xavier_initializer())\n",
    "B1M = tf.Variable(tf.zeros([mH]),name=\"B1M\")\n",
    "layer1M = tf.nn.relu(tf.matmul(previous_state,W1M) + B1M)\n",
    "W2M = tf.get_variable(\"W2M\", shape=[mH, mH],\n",
    "           initializer=tf.contrib.layers.xavier_initializer())\n",
    "B2M = tf.Variable(tf.zeros([mH]),name=\"B2M\")\n",
    "layer2M = tf.nn.relu(tf.matmul(layer1M,W2M) + B2M)\n",
    "wO = tf.get_variable(\"wO\", shape=[mH, 4],\n",
    "           initializer=tf.contrib.layers.xavier_initializer())\n",
    "wR = tf.get_variable(\"wR\", shape=[mH, 1],\n",
    "           initializer=tf.contrib.layers.xavier_initializer())\n",
    "wD = tf.get_variable(\"wD\", shape=[mH, 1],\n",
    "           initializer=tf.contrib.layers.xavier_initializer())\n",
    "\n",
    "bO = tf.Variable(tf.zeros([4]),name=\"bO\")\n",
    "bR = tf.Variable(tf.zeros([1]),name=\"bR\")\n",
    "bD = tf.Variable(tf.ones([1]),name=\"bD\")\n",
    "\n",
    "\n",
    "predicted_observation = tf.matmul(layer2M,wO,name=\"predicted_observation\") + bO\n",
    "predicted_reward = tf.matmul(layer2M,wR,name=\"predicted_reward\") + bR\n",
    "predicted_done = tf.sigmoid(tf.matmul(layer2M,wD,name=\"predicted_done\") + bD)\n",
    "\n",
    "true_observation = tf.placeholder(tf.float32,[None,4],name=\"true_observation\")\n",
    "true_reward = tf.placeholder(tf.float32,[None,1],name=\"true_reward\")\n",
    "true_done = tf.placeholder(tf.float32,[None,1],name=\"true_done\")\n",
    "\n",
    "\n",
    "predicted_state = tf.concat([predicted_observation,predicted_reward,predicted_done],1)\n",
    "\n",
    "observation_loss = tf.square(true_observation - predicted_observation)\n",
    "\n",
    "reward_loss = tf.square(true_reward - predicted_reward)\n",
    "\n",
    "done_loss = tf.multiply(predicted_done, true_done) + tf.multiply(1-predicted_done, 1-true_done)\n",
    "done_loss = -tf.log(done_loss)\n",
    "\n",
    "model_loss = tf.reduce_mean(observation_loss + done_loss + reward_loss)\n",
    "\n",
    "modelAdam = tf.train.AdamOptimizer(learning_rate=learning_rate)\n",
    "updateModel = modelAdam.minimize(model_loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Helper-functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def resetGradBuffer(gradBuffer):\n",
    "    for ix,grad in enumerate(gradBuffer):\n",
    "        gradBuffer[ix] = grad * 0\n",
    "    return gradBuffer\n",
    "\n",
    "def discount_rewards(r):\n",
    "    ################################################################################\n",
    "    # TODO: Implement the discounted rewards function                              #\n",
    "    # Return discounted rewards weighed by gamma. Each reward will be replaced     #\n",
    "    # with a weight reward that involves itself and all the other rewards occuring #\n",
    "    # after it. The later the reward after it happens, the less effect it has on   #\n",
    "    # the current rewards's discounted reward                                      #\n",
    "    # Hint: [r0, r1, r2, ..., r_N] will look someting like:                        #\n",
    "    #       [(r0 + r1*gamma^1 + ... r_N*gamma^N), (r1 + r2*gamma^1 + ...), ...]    #\n",
    "    ################################################################################\n",
    "    pass   \n",
    "    ################################################################################\n",
    "    #                                 END OF YOUR CODE                             #\n",
    "    ################################################################################\n",
    "\n",
    "# This function uses our model to produce a new state when given a previous state and action\n",
    "def stepModel(sess, xs, action):\n",
    "    toFeed = np.reshape(np.hstack([xs[-1][0],np.array(action)]),[1,5])\n",
    "    myPredict = sess.run([predicted_state],feed_dict={previous_state: toFeed})\n",
    "    reward = myPredict[0][:,4]\n",
    "    observation = myPredict[0][:,0:4]\n",
    "    observation[:,0] = np.clip(observation[:,0],-2.4,2.4)\n",
    "    observation[:,2] = np.clip(observation[:,2],-0.4,0.4)\n",
    "    doneP = np.clip(myPredict[0][:,5],0,1)\n",
    "    if doneP > 0.1 or len(xs)>= 300:\n",
    "        done = True\n",
    "    else:\n",
    "        done = False\n",
    "    return observation, reward, done"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training the Policy and Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "World Perf: Episode 4.000000. Reward 33.333333. action: 0.000000. mean reward 33.333333.\n",
      "World Perf: Episode 7.000000. Reward 40.000000. action: 0.000000. mean reward 33.400000.\n",
      "World Perf: Episode 10.000000. Reward 32.666667. action: 1.000000. mean reward 33.392667.\n",
      "World Perf: Episode 13.000000. Reward 39.333333. action: 0.000000. mean reward 33.452073.\n",
      "World Perf: Episode 16.000000. Reward 24.333333. action: 1.000000. mean reward 33.360886.\n",
      "World Perf: Episode 19.000000. Reward 13.666667. action: 1.000000. mean reward 33.163944.\n",
      "World Perf: Episode 22.000000. Reward 19.666667. action: 0.000000. mean reward 33.028971.\n",
      "World Perf: Episode 25.000000. Reward 19.000000. action: 0.000000. mean reward 32.888681.\n",
      "World Perf: Episode 28.000000. Reward 27.333333. action: 1.000000. mean reward 32.833128.\n",
      "World Perf: Episode 31.000000. Reward 27.333333. action: 1.000000. mean reward 32.778130.\n",
      "World Perf: Episode 34.000000. Reward 21.333333. action: 1.000000. mean reward 32.663682.\n",
      "World Perf: Episode 37.000000. Reward 17.666667. action: 1.000000. mean reward 32.513712.\n",
      "World Perf: Episode 40.000000. Reward 31.333333. action: 1.000000. mean reward 32.501908.\n",
      "World Perf: Episode 43.000000. Reward 15.000000. action: 0.000000. mean reward 32.326889.\n",
      "World Perf: Episode 46.000000. Reward 24.666667. action: 1.000000. mean reward 32.250287.\n",
      "World Perf: Episode 49.000000. Reward 25.000000. action: 1.000000. mean reward 32.177784.\n",
      "World Perf: Episode 52.000000. Reward 19.666667. action: 1.000000. mean reward 32.052673.\n",
      "World Perf: Episode 55.000000. Reward 26.666667. action: 1.000000. mean reward 31.998813.\n",
      "World Perf: Episode 58.000000. Reward 37.000000. action: 0.000000. mean reward 32.048824.\n",
      "World Perf: Episode 61.000000. Reward 26.000000. action: 1.000000. mean reward 31.988336.\n",
      "World Perf: Episode 64.000000. Reward 15.666667. action: 1.000000. mean reward 31.825119.\n",
      "World Perf: Episode 67.000000. Reward 33.333333. action: 0.000000. mean reward 31.840202.\n",
      "World Perf: Episode 70.000000. Reward 27.333333. action: 1.000000. mean reward 31.795133.\n",
      "World Perf: Episode 73.000000. Reward 55.666667. action: 0.000000. mean reward 32.033848.\n",
      "World Perf: Episode 76.000000. Reward 18.666667. action: 1.000000. mean reward 31.900176.\n",
      "World Perf: Episode 79.000000. Reward 12.333333. action: 0.000000. mean reward 31.704508.\n",
      "World Perf: Episode 82.000000. Reward 36.666667. action: 1.000000. mean reward 31.754130.\n",
      "World Perf: Episode 85.000000. Reward 21.000000. action: 1.000000. mean reward 31.646588.\n",
      "World Perf: Episode 88.000000. Reward 16.333333. action: 0.000000. mean reward 31.493456.\n",
      "World Perf: Episode 91.000000. Reward 20.333333. action: 1.000000. mean reward 31.381855.\n",
      "World Perf: Episode 94.000000. Reward 31.333333. action: 0.000000. mean reward 31.381369.\n",
      "World Perf: Episode 97.000000. Reward 20.000000. action: 1.000000. mean reward 31.267556.\n",
      "World Perf: Episode 100.000000. Reward 35.333333. action: 1.000000. mean reward 31.308213.\n",
      "World Perf: Episode 103.000000. Reward 39.000000. action: 1.000000. mean reward 31.385131.\n",
      "World Perf: Episode 106.000000. Reward 19.333333. action: 1.000000. mean reward 31.264613.\n",
      "World Perf: Episode 109.000000. Reward 19.333333. action: 1.000000. mean reward 31.145300.\n",
      "World Perf: Episode 112.000000. Reward 41.000000. action: 1.000000. mean reward 31.243847.\n",
      "World Perf: Episode 115.000000. Reward 28.333333. action: 1.000000. mean reward 31.214742.\n",
      "World Perf: Episode 118.000000. Reward 33.666667. action: 1.000000. mean reward 31.239262.\n",
      "World Perf: Episode 121.000000. Reward 35.000000. action: 0.000000. mean reward 31.276869.\n",
      "World Perf: Episode 124.000000. Reward 13.333333. action: 1.000000. mean reward 31.097434.\n",
      "World Perf: Episode 127.000000. Reward 35.000000. action: 1.000000. mean reward 31.136459.\n",
      "World Perf: Episode 130.000000. Reward 14.000000. action: 0.000000. mean reward 30.965095.\n",
      "World Perf: Episode 133.000000. Reward 29.333333. action: 1.000000. mean reward 30.948777.\n",
      "World Perf: Episode 136.000000. Reward 13.000000. action: 1.000000. mean reward 30.769289.\n",
      "World Perf: Episode 139.000000. Reward 28.666667. action: 0.000000. mean reward 30.748263.\n",
      "World Perf: Episode 142.000000. Reward 33.333333. action: 1.000000. mean reward 30.774114.\n",
      "World Perf: Episode 145.000000. Reward 22.000000. action: 1.000000. mean reward 30.686373.\n",
      "World Perf: Episode 148.000000. Reward 29.000000. action: 0.000000. mean reward 30.669509.\n",
      "World Perf: Episode 151.000000. Reward 11.333333. action: 0.000000. mean reward 30.476147.\n",
      "World Perf: Episode 154.000000. Reward 23.333333. action: 1.000000. mean reward 30.404719.\n",
      "World Perf: Episode 157.000000. Reward 21.000000. action: 1.000000. mean reward 30.310672.\n",
      "World Perf: Episode 160.000000. Reward 30.333333. action: 0.000000. mean reward 30.310898.\n",
      "World Perf: Episode 163.000000. Reward 16.333333. action: 1.000000. mean reward 30.171123.\n",
      "World Perf: Episode 166.000000. Reward 25.333333. action: 0.000000. mean reward 30.122745.\n",
      "World Perf: Episode 169.000000. Reward 20.333333. action: 1.000000. mean reward 30.024851.\n",
      "World Perf: Episode 172.000000. Reward 25.666667. action: 1.000000. mean reward 29.981269.\n",
      "World Perf: Episode 175.000000. Reward 26.000000. action: 1.000000. mean reward 29.941456.\n",
      "World Perf: Episode 178.000000. Reward 41.666667. action: 0.000000. mean reward 30.058708.\n",
      "World Perf: Episode 181.000000. Reward 14.000000. action: 0.000000. mean reward 29.898121.\n",
      "World Perf: Episode 184.000000. Reward 28.666667. action: 1.000000. mean reward 29.885807.\n",
      "World Perf: Episode 187.000000. Reward 28.000000. action: 0.000000. mean reward 29.866949.\n",
      "World Perf: Episode 190.000000. Reward 20.000000. action: 1.000000. mean reward 29.768279.\n",
      "World Perf: Episode 193.000000. Reward 25.000000. action: 0.000000. mean reward 29.720596.\n",
      "World Perf: Episode 196.000000. Reward 25.000000. action: 0.000000. mean reward 29.673390.\n",
      "World Perf: Episode 199.000000. Reward 24.000000. action: 0.000000. mean reward 29.616657.\n",
      "World Perf: Episode 202.000000. Reward 27.333333. action: 0.000000. mean reward 29.593823.\n",
      "World Perf: Episode 205.000000. Reward 22.000000. action: 1.000000. mean reward 29.517885.\n",
      "World Perf: Episode 208.000000. Reward 17.333333. action: 1.000000. mean reward 29.396040.\n",
      "World Perf: Episode 211.000000. Reward 17.666667. action: 0.000000. mean reward 29.278746.\n",
      "World Perf: Episode 214.000000. Reward 31.000000. action: 1.000000. mean reward 29.295958.\n",
      "World Perf: Episode 217.000000. Reward 26.333333. action: 0.000000. mean reward 29.266332.\n",
      "World Perf: Episode 220.000000. Reward 15.333333. action: 1.000000. mean reward 29.127002.\n",
      "World Perf: Episode 223.000000. Reward 22.000000. action: 1.000000. mean reward 29.055732.\n",
      "World Perf: Episode 226.000000. Reward 30.333333. action: 1.000000. mean reward 29.068508.\n",
      "World Perf: Episode 229.000000. Reward 22.333333. action: 1.000000. mean reward 29.001156.\n",
      "World Perf: Episode 232.000000. Reward 31.333333. action: 0.000000. mean reward 29.024478.\n",
      "World Perf: Episode 235.000000. Reward 33.333333. action: 0.000000. mean reward 29.067567.\n",
      "World Perf: Episode 238.000000. Reward 47.000000. action: 0.000000. mean reward 29.246891.\n",
      "World Perf: Episode 241.000000. Reward 24.666667. action: 1.000000. mean reward 29.201089.\n",
      "World Perf: Episode 244.000000. Reward 25.333333. action: 1.000000. mean reward 29.162411.\n",
      "World Perf: Episode 247.000000. Reward 34.000000. action: 1.000000. mean reward 29.210787.\n",
      "World Perf: Episode 250.000000. Reward 26.333333. action: 0.000000. mean reward 29.182013.\n",
      "World Perf: Episode 253.000000. Reward 27.000000. action: 1.000000. mean reward 29.160192.\n",
      "World Perf: Episode 256.000000. Reward 32.666667. action: 1.000000. mean reward 29.195257.\n",
      "World Perf: Episode 259.000000. Reward 35.666667. action: 1.000000. mean reward 29.259971.\n",
      "World Perf: Episode 262.000000. Reward 35.666667. action: 1.000000. mean reward 29.324038.\n",
      "World Perf: Episode 265.000000. Reward 23.333333. action: 1.000000. mean reward 29.264131.\n",
      "World Perf: Episode 268.000000. Reward 23.666667. action: 0.000000. mean reward 29.208157.\n",
      "World Perf: Episode 271.000000. Reward 22.666667. action: 0.000000. mean reward 29.142742.\n",
      "World Perf: Episode 274.000000. Reward 34.333333. action: 0.000000. mean reward 29.194648.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "World Perf: Episode 277.000000. Reward 41.000000. action: 1.000000. mean reward 29.312701.\n",
      "World Perf: Episode 280.000000. Reward 16.333333. action: 1.000000. mean reward 29.182907.\n",
      "World Perf: Episode 283.000000. Reward 29.000000. action: 1.000000. mean reward 29.181078.\n",
      "World Perf: Episode 286.000000. Reward 45.333333. action: 1.000000. mean reward 29.342601.\n",
      "World Perf: Episode 289.000000. Reward 25.666667. action: 1.000000. mean reward 29.305842.\n",
      "World Perf: Episode 292.000000. Reward 17.666667. action: 1.000000. mean reward 29.189450.\n",
      "World Perf: Episode 295.000000. Reward 20.666667. action: 0.000000. mean reward 29.104222.\n",
      "World Perf: Episode 298.000000. Reward 16.333333. action: 1.000000. mean reward 28.976513.\n",
      "World Perf: Episode 301.000000. Reward 26.666667. action: 0.000000. mean reward 28.953415.\n",
      "World Perf: Episode 304.000000. Reward 40.333333. action: 1.000000. mean reward 29.067214.\n",
      "World Perf: Episode 307.000000. Reward 16.666667. action: 1.000000. mean reward 28.943208.\n",
      "World Perf: Episode 310.000000. Reward 33.333333. action: 1.000000. mean reward 28.987110.\n",
      "World Perf: Episode 313.000000. Reward 25.000000. action: 1.000000. mean reward 28.947238.\n",
      "World Perf: Episode 316.000000. Reward 22.000000. action: 1.000000. mean reward 28.877766.\n",
      "World Perf: Episode 319.000000. Reward 28.333333. action: 1.000000. mean reward 28.872322.\n",
      "World Perf: Episode 322.000000. Reward 16.000000. action: 1.000000. mean reward 28.743599.\n",
      "World Perf: Episode 325.000000. Reward 28.666667. action: 0.000000. mean reward 28.742829.\n",
      "World Perf: Episode 328.000000. Reward 37.666667. action: 0.000000. mean reward 28.832068.\n",
      "World Perf: Episode 331.000000. Reward 32.000000. action: 0.000000. mean reward 28.863747.\n",
      "World Perf: Episode 334.000000. Reward 35.000000. action: 1.000000. mean reward 28.925109.\n",
      "World Perf: Episode 337.000000. Reward 19.666667. action: 1.000000. mean reward 28.832525.\n",
      "World Perf: Episode 340.000000. Reward 25.000000. action: 0.000000. mean reward 28.794200.\n",
      "World Perf: Episode 343.000000. Reward 27.000000. action: 1.000000. mean reward 28.776258.\n",
      "World Perf: Episode 346.000000. Reward 27.000000. action: 1.000000. mean reward 28.758495.\n",
      "World Perf: Episode 349.000000. Reward 27.000000. action: 0.000000. mean reward 28.740910.\n",
      "World Perf: Episode 352.000000. Reward 18.666667. action: 0.000000. mean reward 28.640168.\n",
      "World Perf: Episode 355.000000. Reward 24.666667. action: 0.000000. mean reward 28.600433.\n",
      "World Perf: Episode 358.000000. Reward 17.333333. action: 0.000000. mean reward 28.487762.\n",
      "World Perf: Episode 361.000000. Reward 34.000000. action: 0.000000. mean reward 28.542884.\n",
      "World Perf: Episode 364.000000. Reward 27.333333. action: 0.000000. mean reward 28.530789.\n",
      "World Perf: Episode 367.000000. Reward 37.666667. action: 1.000000. mean reward 28.622147.\n",
      "World Perf: Episode 370.000000. Reward 15.333333. action: 1.000000. mean reward 28.489259.\n",
      "World Perf: Episode 373.000000. Reward 23.333333. action: 1.000000. mean reward 28.437700.\n",
      "World Perf: Episode 376.000000. Reward 24.000000. action: 1.000000. mean reward 28.393323.\n",
      "World Perf: Episode 379.000000. Reward 49.666667. action: 0.000000. mean reward 28.606056.\n",
      "World Perf: Episode 382.000000. Reward 28.000000. action: 0.000000. mean reward 28.599996.\n",
      "World Perf: Episode 385.000000. Reward 23.000000. action: 0.000000. mean reward 28.543996.\n",
      "World Perf: Episode 388.000000. Reward 26.000000. action: 1.000000. mean reward 28.518556.\n",
      "World Perf: Episode 391.000000. Reward 30.000000. action: 1.000000. mean reward 28.533370.\n",
      "World Perf: Episode 394.000000. Reward 11.666667. action: 1.000000. mean reward 28.364703.\n",
      "World Perf: Episode 397.000000. Reward 34.000000. action: 0.000000. mean reward 28.421056.\n",
      "World Perf: Episode 400.000000. Reward 26.666667. action: 0.000000. mean reward 28.403512.\n",
      "World Perf: Episode 403.000000. Reward 34.666667. action: 1.000000. mean reward 28.466144.\n",
      "World Perf: Episode 406.000000. Reward 23.000000. action: 1.000000. mean reward 28.411483.\n",
      "World Perf: Episode 409.000000. Reward 20.333333. action: 0.000000. mean reward 28.330701.\n",
      "World Perf: Episode 412.000000. Reward 19.000000. action: 1.000000. mean reward 28.237394.\n",
      "World Perf: Episode 415.000000. Reward 26.666667. action: 0.000000. mean reward 28.221687.\n",
      "World Perf: Episode 418.000000. Reward 25.333333. action: 0.000000. mean reward 28.192803.\n",
      "World Perf: Episode 421.000000. Reward 47.666667. action: 1.000000. mean reward 28.387542.\n",
      "World Perf: Episode 424.000000. Reward 26.333333. action: 1.000000. mean reward 28.367000.\n",
      "World Perf: Episode 427.000000. Reward 22.666667. action: 1.000000. mean reward 28.309996.\n",
      "World Perf: Episode 430.000000. Reward 27.666667. action: 0.000000. mean reward 28.303563.\n",
      "World Perf: Episode 433.000000. Reward 33.666667. action: 1.000000. mean reward 28.357194.\n",
      "World Perf: Episode 436.000000. Reward 17.000000. action: 0.000000. mean reward 28.243622.\n",
      "World Perf: Episode 439.000000. Reward 17.333333. action: 0.000000. mean reward 28.134519.\n",
      "World Perf: Episode 442.000000. Reward 46.000000. action: 1.000000. mean reward 28.313174.\n",
      "World Perf: Episode 445.000000. Reward 20.666667. action: 0.000000. mean reward 28.236709.\n",
      "World Perf: Episode 448.000000. Reward 25.666667. action: 1.000000. mean reward 28.211009.\n",
      "World Perf: Episode 451.000000. Reward 46.000000. action: 1.000000. mean reward 28.388899.\n",
      "World Perf: Episode 454.000000. Reward 26.666667. action: 0.000000. mean reward 28.371676.\n",
      "World Perf: Episode 457.000000. Reward 35.000000. action: 1.000000. mean reward 28.437960.\n",
      "World Perf: Episode 460.000000. Reward 41.000000. action: 0.000000. mean reward 28.563580.\n",
      "World Perf: Episode 463.000000. Reward 35.000000. action: 1.000000. mean reward 28.627944.\n",
      "World Perf: Episode 466.000000. Reward 13.666667. action: 0.000000. mean reward 28.478331.\n",
      "World Perf: Episode 469.000000. Reward 37.000000. action: 1.000000. mean reward 28.563548.\n",
      "World Perf: Episode 472.000000. Reward 54.000000. action: 1.000000. mean reward 28.817913.\n",
      "World Perf: Episode 475.000000. Reward 22.666667. action: 0.000000. mean reward 28.756400.\n",
      "World Perf: Episode 478.000000. Reward 30.666667. action: 1.000000. mean reward 28.775503.\n",
      "World Perf: Episode 481.000000. Reward 19.000000. action: 1.000000. mean reward 28.677748.\n",
      "World Perf: Episode 484.000000. Reward 27.333333. action: 0.000000. mean reward 28.664304.\n",
      "World Perf: Episode 487.000000. Reward 23.666667. action: 0.000000. mean reward 28.614327.\n",
      "World Perf: Episode 490.000000. Reward 34.666667. action: 1.000000. mean reward 28.674851.\n",
      "World Perf: Episode 493.000000. Reward 34.666667. action: 1.000000. mean reward 28.734769.\n",
      "World Perf: Episode 496.000000. Reward 26.333333. action: 0.000000. mean reward 28.710754.\n",
      "World Perf: Episode 499.000000. Reward 26.000000. action: 0.000000. mean reward 28.683647.\n",
      "World Perf: Episode 502.000000. Reward 27.333333. action: 1.000000. mean reward 28.670144.\n",
      "World Perf: Episode 505.000000. Reward 20.666667. action: 1.000000. mean reward 28.590109.\n",
      "World Perf: Episode 508.000000. Reward 18.333333. action: 1.000000. mean reward 28.487541.\n",
      "World Perf: Episode 511.000000. Reward 23.000000. action: 0.000000. mean reward 28.432666.\n",
      "World Perf: Episode 514.000000. Reward 21.000000. action: 1.000000. mean reward 28.358339.\n",
      "World Perf: Episode 517.000000. Reward 13.333333. action: 0.000000. mean reward 28.208089.\n",
      "World Perf: Episode 520.000000. Reward 16.333333. action: 1.000000. mean reward 28.089342.\n",
      "World Perf: Episode 523.000000. Reward 37.333333. action: 1.000000. mean reward 28.181781.\n",
      "World Perf: Episode 526.000000. Reward 50.666667. action: 1.000000. mean reward 28.406630.\n",
      "World Perf: Episode 529.000000. Reward 42.333333. action: 1.000000. mean reward 28.545897.\n",
      "World Perf: Episode 532.000000. Reward 13.000000. action: 0.000000. mean reward 28.390438.\n",
      "World Perf: Episode 535.000000. Reward 49.000000. action: 0.000000. mean reward 28.596534.\n",
      "World Perf: Episode 538.000000. Reward 19.000000. action: 1.000000. mean reward 28.500569.\n",
      "World Perf: Episode 541.000000. Reward 16.333333. action: 1.000000. mean reward 28.378896.\n",
      "World Perf: Episode 544.000000. Reward 12.333333. action: 0.000000. mean reward 28.218441.\n",
      "World Perf: Episode 547.000000. Reward 22.000000. action: 1.000000. mean reward 28.156256.\n",
      "World Perf: Episode 550.000000. Reward 31.666667. action: 0.000000. mean reward 28.191360.\n",
      "World Perf: Episode 553.000000. Reward 28.333333. action: 0.000000. mean reward 28.192780.\n",
      "World Perf: Episode 556.000000. Reward 37.666667. action: 0.000000. mean reward 28.287519.\n",
      "World Perf: Episode 559.000000. Reward 23.666667. action: 0.000000. mean reward 28.241310.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "World Perf: Episode 562.000000. Reward 27.333333. action: 1.000000. mean reward 28.232231.\n",
      "World Perf: Episode 565.000000. Reward 15.333333. action: 1.000000. mean reward 28.103242.\n",
      "World Perf: Episode 568.000000. Reward 24.000000. action: 0.000000. mean reward 28.062209.\n",
      "World Perf: Episode 571.000000. Reward 21.666667. action: 1.000000. mean reward 27.998254.\n",
      "World Perf: Episode 574.000000. Reward 32.333333. action: 1.000000. mean reward 28.041605.\n",
      "World Perf: Episode 577.000000. Reward 17.333333. action: 0.000000. mean reward 27.934522.\n",
      "World Perf: Episode 580.000000. Reward 27.666667. action: 0.000000. mean reward 27.931843.\n",
      "World Perf: Episode 583.000000. Reward 29.000000. action: 1.000000. mean reward 27.942525.\n",
      "World Perf: Episode 586.000000. Reward 32.000000. action: 1.000000. mean reward 27.983100.\n",
      "World Perf: Episode 589.000000. Reward 26.666667. action: 0.000000. mean reward 27.969935.\n",
      "World Perf: Episode 592.000000. Reward 21.666667. action: 1.000000. mean reward 27.906903.\n",
      "World Perf: Episode 595.000000. Reward 39.000000. action: 0.000000. mean reward 28.017834.\n",
      "World Perf: Episode 598.000000. Reward 12.333333. action: 1.000000. mean reward 27.860989.\n",
      "World Perf: Episode 601.000000. Reward 21.333333. action: 0.000000. mean reward 27.795712.\n",
      "World Perf: Episode 604.000000. Reward 14.333333. action: 1.000000. mean reward 27.661088.\n",
      "World Perf: Episode 607.000000. Reward 34.000000. action: 0.000000. mean reward 27.724477.\n",
      "World Perf: Episode 610.000000. Reward 40.000000. action: 0.000000. mean reward 27.847233.\n",
      "World Perf: Episode 613.000000. Reward 25.666667. action: 0.000000. mean reward 27.825427.\n",
      "World Perf: Episode 616.000000. Reward 39.333333. action: 0.000000. mean reward 27.940506.\n",
      "World Perf: Episode 619.000000. Reward 24.666667. action: 0.000000. mean reward 27.907768.\n",
      "World Perf: Episode 622.000000. Reward 42.666667. action: 0.000000. mean reward 28.055357.\n",
      "World Perf: Episode 625.000000. Reward 30.333333. action: 1.000000. mean reward 28.078136.\n",
      "World Perf: Episode 628.000000. Reward 25.666667. action: 1.000000. mean reward 28.054022.\n",
      "World Perf: Episode 631.000000. Reward 28.000000. action: 1.000000. mean reward 28.053481.\n",
      "World Perf: Episode 634.000000. Reward 34.000000. action: 0.000000. mean reward 28.112947.\n",
      "World Perf: Episode 637.000000. Reward 24.000000. action: 1.000000. mean reward 28.071817.\n",
      "World Perf: Episode 640.000000. Reward 17.666667. action: 0.000000. mean reward 27.967766.\n",
      "World Perf: Episode 643.000000. Reward 19.333333. action: 1.000000. mean reward 27.881421.\n",
      "World Perf: Episode 646.000000. Reward 48.000000. action: 0.000000. mean reward 28.082607.\n",
      "World Perf: Episode 649.000000. Reward 18.333333. action: 1.000000. mean reward 27.985114.\n",
      "World Perf: Episode 652.000000. Reward 27.666667. action: 0.000000. mean reward 27.981930.\n",
      "World Perf: Episode 655.000000. Reward 28.000000. action: 0.000000. mean reward 27.982111.\n",
      "World Perf: Episode 658.000000. Reward 31.000000. action: 1.000000. mean reward 28.012290.\n",
      "World Perf: Episode 661.000000. Reward 14.000000. action: 0.000000. mean reward 27.872167.\n",
      "World Perf: Episode 664.000000. Reward 14.000000. action: 1.000000. mean reward 27.733445.\n",
      "World Perf: Episode 667.000000. Reward 19.333333. action: 1.000000. mean reward 27.649444.\n",
      "World Perf: Episode 670.000000. Reward 31.000000. action: 1.000000. mean reward 27.682949.\n",
      "World Perf: Episode 673.000000. Reward 31.666667. action: 1.000000. mean reward 27.722787.\n",
      "World Perf: Episode 676.000000. Reward 17.666667. action: 1.000000. mean reward 27.622225.\n",
      "World Perf: Episode 679.000000. Reward 27.000000. action: 0.000000. mean reward 27.616003.\n",
      "World Perf: Episode 682.000000. Reward 17.666667. action: 1.000000. mean reward 27.516510.\n",
      "World Perf: Episode 685.000000. Reward 34.666667. action: 1.000000. mean reward 27.588011.\n",
      "World Perf: Episode 688.000000. Reward 39.666667. action: 0.000000. mean reward 27.708798.\n",
      "World Perf: Episode 691.000000. Reward 15.666667. action: 0.000000. mean reward 27.588377.\n",
      "World Perf: Episode 694.000000. Reward 31.333333. action: 1.000000. mean reward 27.625826.\n",
      "World Perf: Episode 697.000000. Reward 20.333333. action: 0.000000. mean reward 27.552901.\n",
      "World Perf: Episode 700.000000. Reward 27.666667. action: 1.000000. mean reward 27.554039.\n",
      "World Perf: Episode 703.000000. Reward 42.666667. action: 1.000000. mean reward 27.705165.\n",
      "World Perf: Episode 706.000000. Reward 29.333333. action: 1.000000. mean reward 27.721447.\n",
      "World Perf: Episode 709.000000. Reward 16.000000. action: 1.000000. mean reward 27.604232.\n",
      "World Perf: Episode 712.000000. Reward 13.666667. action: 1.000000. mean reward 27.464857.\n",
      "World Perf: Episode 715.000000. Reward 17.333333. action: 1.000000. mean reward 27.363541.\n",
      "World Perf: Episode 718.000000. Reward 44.000000. action: 1.000000. mean reward 27.529906.\n",
      "World Perf: Episode 721.000000. Reward 17.666667. action: 1.000000. mean reward 27.431274.\n",
      "World Perf: Episode 724.000000. Reward 28.000000. action: 0.000000. mean reward 27.436961.\n",
      "World Perf: Episode 727.000000. Reward 20.000000. action: 1.000000. mean reward 27.362591.\n",
      "World Perf: Episode 730.000000. Reward 27.000000. action: 1.000000. mean reward 27.358965.\n",
      "World Perf: Episode 733.000000. Reward 18.000000. action: 0.000000. mean reward 27.265376.\n",
      "World Perf: Episode 736.000000. Reward 18.000000. action: 1.000000. mean reward 27.172722.\n",
      "World Perf: Episode 739.000000. Reward 14.000000. action: 0.000000. mean reward 27.040995.\n",
      "World Perf: Episode 742.000000. Reward 15.333333. action: 1.000000. mean reward 26.923918.\n",
      "World Perf: Episode 745.000000. Reward 14.333333. action: 0.000000. mean reward 26.798012.\n",
      "World Perf: Episode 748.000000. Reward 18.000000. action: 1.000000. mean reward 26.710032.\n",
      "World Perf: Episode 751.000000. Reward 16.000000. action: 1.000000. mean reward 26.602932.\n",
      "World Perf: Episode 754.000000. Reward 26.000000. action: 0.000000. mean reward 26.596903.\n",
      "World Perf: Episode 757.000000. Reward 31.000000. action: 1.000000. mean reward 26.640934.\n",
      "World Perf: Episode 760.000000. Reward 29.666667. action: 0.000000. mean reward 26.671191.\n",
      "World Perf: Episode 763.000000. Reward 27.000000. action: 1.000000. mean reward 26.674479.\n",
      "World Perf: Episode 766.000000. Reward 20.666667. action: 1.000000. mean reward 26.614401.\n",
      "World Perf: Episode 769.000000. Reward 40.333333. action: 1.000000. mean reward 26.751590.\n",
      "World Perf: Episode 772.000000. Reward 25.000000. action: 1.000000. mean reward 26.734074.\n",
      "World Perf: Episode 775.000000. Reward 20.666667. action: 0.000000. mean reward 26.673400.\n",
      "World Perf: Episode 778.000000. Reward 29.000000. action: 0.000000. mean reward 26.696666.\n",
      "World Perf: Episode 781.000000. Reward 29.333333. action: 1.000000. mean reward 26.723033.\n",
      "World Perf: Episode 784.000000. Reward 29.333333. action: 1.000000. mean reward 26.749136.\n",
      "World Perf: Episode 787.000000. Reward 17.666667. action: 1.000000. mean reward 26.658311.\n",
      "World Perf: Episode 790.000000. Reward 36.333333. action: 0.000000. mean reward 26.755061.\n",
      "World Perf: Episode 793.000000. Reward 31.333333. action: 0.000000. mean reward 26.800844.\n",
      "World Perf: Episode 796.000000. Reward 24.000000. action: 1.000000. mean reward 26.772836.\n",
      "World Perf: Episode 799.000000. Reward 24.000000. action: 0.000000. mean reward 26.745107.\n",
      "World Perf: Episode 802.000000. Reward 24.333333. action: 1.000000. mean reward 26.720990.\n",
      "World Perf: Episode 805.000000. Reward 18.666667. action: 0.000000. mean reward 26.640446.\n",
      "World Perf: Episode 808.000000. Reward 14.666667. action: 1.000000. mean reward 26.520709.\n",
      "World Perf: Episode 811.000000. Reward 43.000000. action: 1.000000. mean reward 26.685501.\n",
      "World Perf: Episode 814.000000. Reward 15.000000. action: 1.000000. mean reward 26.568646.\n",
      "World Perf: Episode 817.000000. Reward 25.666667. action: 1.000000. mean reward 26.559627.\n",
      "World Perf: Episode 820.000000. Reward 12.666667. action: 0.000000. mean reward 26.420697.\n",
      "World Perf: Episode 823.000000. Reward 21.000000. action: 1.000000. mean reward 26.366490.\n",
      "World Perf: Episode 826.000000. Reward 31.000000. action: 1.000000. mean reward 26.412825.\n",
      "World Perf: Episode 829.000000. Reward 20.666667. action: 0.000000. mean reward 26.355364.\n",
      "World Perf: Episode 832.000000. Reward 22.666667. action: 0.000000. mean reward 26.318477.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "World Perf: Episode 835.000000. Reward 46.000000. action: 0.000000. mean reward 26.515292.\n",
      "World Perf: Episode 838.000000. Reward 34.666667. action: 0.000000. mean reward 26.596806.\n",
      "World Perf: Episode 841.000000. Reward 34.000000. action: 1.000000. mean reward 26.670838.\n",
      "World Perf: Episode 844.000000. Reward 26.333333. action: 0.000000. mean reward 26.667463.\n",
      "World Perf: Episode 847.000000. Reward 22.000000. action: 0.000000. mean reward 26.620788.\n",
      "World Perf: Episode 850.000000. Reward 35.333333. action: 1.000000. mean reward 26.707913.\n",
      "World Perf: Episode 853.000000. Reward 13.666667. action: 1.000000. mean reward 26.577501.\n",
      "World Perf: Episode 856.000000. Reward 15.000000. action: 0.000000. mean reward 26.461726.\n",
      "World Perf: Episode 859.000000. Reward 19.333333. action: 1.000000. mean reward 26.390442.\n",
      "World Perf: Episode 862.000000. Reward 13.666667. action: 1.000000. mean reward 26.263204.\n",
      "World Perf: Episode 865.000000. Reward 17.000000. action: 0.000000. mean reward 26.170572.\n",
      "World Perf: Episode 868.000000. Reward 23.666667. action: 1.000000. mean reward 26.145533.\n",
      "World Perf: Episode 871.000000. Reward 28.333333. action: 1.000000. mean reward 26.167411.\n",
      "World Perf: Episode 874.000000. Reward 38.000000. action: 1.000000. mean reward 26.285737.\n",
      "World Perf: Episode 877.000000. Reward 26.000000. action: 1.000000. mean reward 26.282880.\n",
      "World Perf: Episode 880.000000. Reward 13.666667. action: 0.000000. mean reward 26.156717.\n",
      "World Perf: Episode 883.000000. Reward 39.333333. action: 1.000000. mean reward 26.288484.\n",
      "World Perf: Episode 886.000000. Reward 23.000000. action: 0.000000. mean reward 26.255599.\n",
      "World Perf: Episode 889.000000. Reward 20.666667. action: 1.000000. mean reward 26.199709.\n",
      "World Perf: Episode 892.000000. Reward 15.333333. action: 0.000000. mean reward 26.091046.\n",
      "World Perf: Episode 895.000000. Reward 36.000000. action: 1.000000. mean reward 26.190135.\n",
      "World Perf: Episode 898.000000. Reward 38.333333. action: 0.000000. mean reward 26.311567.\n",
      "World Perf: Episode 901.000000. Reward 22.000000. action: 1.000000. mean reward 26.268452.\n",
      "World Perf: Episode 904.000000. Reward 19.333333. action: 0.000000. mean reward 26.199100.\n",
      "World Perf: Episode 907.000000. Reward 23.333333. action: 0.000000. mean reward 26.170443.\n",
      "World Perf: Episode 910.000000. Reward 27.333333. action: 1.000000. mean reward 26.182072.\n",
      "World Perf: Episode 913.000000. Reward 37.666667. action: 1.000000. mean reward 26.296918.\n",
      "World Perf: Episode 916.000000. Reward 38.666667. action: 1.000000. mean reward 26.420615.\n",
      "World Perf: Episode 919.000000. Reward 24.666667. action: 1.000000. mean reward 26.403076.\n",
      "World Perf: Episode 922.000000. Reward 19.000000. action: 0.000000. mean reward 26.329045.\n",
      "World Perf: Episode 925.000000. Reward 23.000000. action: 1.000000. mean reward 26.295754.\n",
      "World Perf: Episode 928.000000. Reward 31.000000. action: 1.000000. mean reward 26.342797.\n",
      "World Perf: Episode 931.000000. Reward 20.666667. action: 0.000000. mean reward 26.286036.\n",
      "World Perf: Episode 934.000000. Reward 38.333333. action: 0.000000. mean reward 26.406509.\n",
      "World Perf: Episode 937.000000. Reward 18.666667. action: 1.000000. mean reward 26.329110.\n",
      "World Perf: Episode 940.000000. Reward 21.000000. action: 1.000000. mean reward 26.275819.\n",
      "World Perf: Episode 943.000000. Reward 24.333333. action: 1.000000. mean reward 26.256394.\n",
      "World Perf: Episode 946.000000. Reward 15.000000. action: 1.000000. mean reward 26.143830.\n",
      "World Perf: Episode 949.000000. Reward 19.000000. action: 1.000000. mean reward 26.072392.\n",
      "World Perf: Episode 952.000000. Reward 28.000000. action: 1.000000. mean reward 26.091668.\n",
      "World Perf: Episode 955.000000. Reward 26.666667. action: 1.000000. mean reward 26.097418.\n",
      "World Perf: Episode 958.000000. Reward 17.333333. action: 1.000000. mean reward 26.009777.\n",
      "World Perf: Episode 961.000000. Reward 36.000000. action: 1.000000. mean reward 26.109679.\n",
      "World Perf: Episode 964.000000. Reward 24.666667. action: 0.000000. mean reward 26.095249.\n",
      "World Perf: Episode 967.000000. Reward 23.666667. action: 1.000000. mean reward 26.070963.\n",
      "World Perf: Episode 970.000000. Reward 18.666667. action: 0.000000. mean reward 25.996920.\n",
      "World Perf: Episode 973.000000. Reward 22.333333. action: 1.000000. mean reward 25.960285.\n",
      "World Perf: Episode 976.000000. Reward 17.666667. action: 0.000000. mean reward 25.877348.\n",
      "World Perf: Episode 979.000000. Reward 28.333333. action: 1.000000. mean reward 25.901908.\n",
      "World Perf: Episode 982.000000. Reward 42.000000. action: 0.000000. mean reward 26.062889.\n",
      "World Perf: Episode 985.000000. Reward 29.666667. action: 0.000000. mean reward 26.098927.\n",
      "World Perf: Episode 988.000000. Reward 15.666667. action: 1.000000. mean reward 25.994604.\n",
      "World Perf: Episode 991.000000. Reward 29.000000. action: 0.000000. mean reward 26.024658.\n",
      "World Perf: Episode 994.000000. Reward 29.000000. action: 1.000000. mean reward 26.054412.\n",
      "World Perf: Episode 997.000000. Reward 24.333333. action: 1.000000. mean reward 26.037201.\n",
      "World Perf: Episode 1000.000000. Reward 27.333333. action: 1.000000. mean reward 26.050162.\n",
      "World Perf: Episode 1003.000000. Reward 21.000000. action: 0.000000. mean reward 25.999661.\n",
      "World Perf: Episode 1006.000000. Reward 20.666667. action: 1.000000. mean reward 25.946331.\n",
      "World Perf: Episode 1009.000000. Reward 15.333333. action: 1.000000. mean reward 25.840201.\n",
      "World Perf: Episode 1012.000000. Reward 18.666667. action: 1.000000. mean reward 25.768465.\n",
      "World Perf: Episode 1015.000000. Reward 43.666667. action: 0.000000. mean reward 25.947447.\n",
      "World Perf: Episode 1018.000000. Reward 20.666667. action: 1.000000. mean reward 25.894640.\n",
      "World Perf: Episode 1021.000000. Reward 18.666667. action: 1.000000. mean reward 25.822360.\n",
      "World Perf: Episode 1024.000000. Reward 16.333333. action: 0.000000. mean reward 25.727470.\n",
      "World Perf: Episode 1027.000000. Reward 40.666667. action: 1.000000. mean reward 25.876862.\n",
      "World Perf: Episode 1030.000000. Reward 22.000000. action: 1.000000. mean reward 25.838093.\n",
      "World Perf: Episode 1033.000000. Reward 17.666667. action: 1.000000. mean reward 25.756379.\n",
      "World Perf: Episode 1036.000000. Reward 18.000000. action: 1.000000. mean reward 25.678815.\n",
      "World Perf: Episode 1039.000000. Reward 16.333333. action: 0.000000. mean reward 25.585360.\n",
      "World Perf: Episode 1042.000000. Reward 20.333333. action: 1.000000. mean reward 25.532840.\n",
      "World Perf: Episode 1045.000000. Reward 29.666667. action: 1.000000. mean reward 25.574178.\n",
      "World Perf: Episode 1048.000000. Reward 25.666667. action: 0.000000. mean reward 25.575103.\n",
      "World Perf: Episode 1051.000000. Reward 37.333333. action: 1.000000. mean reward 25.692685.\n",
      "World Perf: Episode 1054.000000. Reward 14.666667. action: 0.000000. mean reward 25.582425.\n",
      "World Perf: Episode 1057.000000. Reward 20.333333. action: 0.000000. mean reward 25.529934.\n",
      "World Perf: Episode 1060.000000. Reward 26.333333. action: 1.000000. mean reward 25.537968.\n",
      "World Perf: Episode 1063.000000. Reward 40.333333. action: 1.000000. mean reward 25.685922.\n",
      "World Perf: Episode 1066.000000. Reward 32.000000. action: 1.000000. mean reward 25.749063.\n",
      "World Perf: Episode 1069.000000. Reward 27.000000. action: 1.000000. mean reward 25.761572.\n",
      "World Perf: Episode 1072.000000. Reward 22.000000. action: 1.000000. mean reward 25.723956.\n",
      "World Perf: Episode 1075.000000. Reward 19.666667. action: 0.000000. mean reward 25.663383.\n",
      "World Perf: Episode 1078.000000. Reward 21.666667. action: 0.000000. mean reward 25.623416.\n",
      "World Perf: Episode 1081.000000. Reward 26.000000. action: 1.000000. mean reward 25.627182.\n",
      "World Perf: Episode 1084.000000. Reward 20.000000. action: 0.000000. mean reward 25.570910.\n",
      "World Perf: Episode 1087.000000. Reward 23.000000. action: 1.000000. mean reward 25.545201.\n",
      "World Perf: Episode 1090.000000. Reward 21.000000. action: 0.000000. mean reward 25.499749.\n",
      "World Perf: Episode 1093.000000. Reward 20.000000. action: 1.000000. mean reward 25.444752.\n",
      "World Perf: Episode 1096.000000. Reward 15.000000. action: 0.000000. mean reward 25.340304.\n",
      "World Perf: Episode 1099.000000. Reward 15.666667. action: 1.000000. mean reward 25.243568.\n",
      "World Perf: Episode 1102.000000. Reward 44.666667. action: 1.000000. mean reward 25.437799.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "World Perf: Episode 1105.000000. Reward 25.000000. action: 1.000000. mean reward 25.433421.\n",
      "World Perf: Episode 1108.000000. Reward 24.333333. action: 1.000000. mean reward 25.422420.\n",
      "World Perf: Episode 1111.000000. Reward 36.000000. action: 1.000000. mean reward 25.528196.\n",
      "World Perf: Episode 1114.000000. Reward 28.666667. action: 1.000000. mean reward 25.559580.\n",
      "World Perf: Episode 1117.000000. Reward 25.333333. action: 0.000000. mean reward 25.557318.\n",
      "World Perf: Episode 1120.000000. Reward 18.333333. action: 0.000000. mean reward 25.485078.\n",
      "World Perf: Episode 1123.000000. Reward 31.000000. action: 1.000000. mean reward 25.540227.\n",
      "World Perf: Episode 1126.000000. Reward 21.000000. action: 1.000000. mean reward 25.494825.\n",
      "World Perf: Episode 1129.000000. Reward 36.333333. action: 0.000000. mean reward 25.603210.\n",
      "World Perf: Episode 1132.000000. Reward 25.666667. action: 1.000000. mean reward 25.603845.\n",
      "World Perf: Episode 1135.000000. Reward 32.666667. action: 0.000000. mean reward 25.674473.\n",
      "World Perf: Episode 1138.000000. Reward 22.666667. action: 1.000000. mean reward 25.644395.\n",
      "World Perf: Episode 1141.000000. Reward 24.000000. action: 1.000000. mean reward 25.627951.\n",
      "World Perf: Episode 1144.000000. Reward 19.333333. action: 0.000000. mean reward 25.565005.\n",
      "World Perf: Episode 1147.000000. Reward 19.666667. action: 1.000000. mean reward 25.506021.\n",
      "World Perf: Episode 1150.000000. Reward 26.000000. action: 1.000000. mean reward 25.510961.\n",
      "World Perf: Episode 1153.000000. Reward 31.666667. action: 0.000000. mean reward 25.572518.\n",
      "World Perf: Episode 1156.000000. Reward 16.000000. action: 1.000000. mean reward 25.476793.\n",
      "World Perf: Episode 1159.000000. Reward 20.333333. action: 0.000000. mean reward 25.425358.\n",
      "World Perf: Episode 1162.000000. Reward 26.000000. action: 1.000000. mean reward 25.431105.\n",
      "World Perf: Episode 1165.000000. Reward 27.000000. action: 0.000000. mean reward 25.446794.\n",
      "World Perf: Episode 1168.000000. Reward 23.333333. action: 0.000000. mean reward 25.425659.\n",
      "World Perf: Episode 1171.000000. Reward 15.666667. action: 1.000000. mean reward 25.328069.\n",
      "World Perf: Episode 1174.000000. Reward 22.333333. action: 1.000000. mean reward 25.298122.\n",
      "World Perf: Episode 1177.000000. Reward 19.333333. action: 0.000000. mean reward 25.238474.\n",
      "World Perf: Episode 1180.000000. Reward 23.333333. action: 1.000000. mean reward 25.219423.\n",
      "World Perf: Episode 1183.000000. Reward 47.000000. action: 1.000000. mean reward 25.437228.\n",
      "World Perf: Episode 1186.000000. Reward 18.666667. action: 0.000000. mean reward 25.369523.\n",
      "World Perf: Episode 1189.000000. Reward 27.000000. action: 1.000000. mean reward 25.385827.\n",
      "World Perf: Episode 1192.000000. Reward 11.000000. action: 1.000000. mean reward 25.241969.\n",
      "World Perf: Episode 1195.000000. Reward 31.666667. action: 1.000000. mean reward 25.306216.\n",
      "World Perf: Episode 1198.000000. Reward 29.000000. action: 1.000000. mean reward 25.343154.\n",
      "World Perf: Episode 1201.000000. Reward 30.333333. action: 0.000000. mean reward 25.393056.\n",
      "World Perf: Episode 1204.000000. Reward 29.333333. action: 1.000000. mean reward 25.432459.\n",
      "World Perf: Episode 1207.000000. Reward 28.333333. action: 0.000000. mean reward 25.461467.\n",
      "World Perf: Episode 1210.000000. Reward 13.666667. action: 1.000000. mean reward 25.343519.\n",
      "World Perf: Episode 1213.000000. Reward 22.666667. action: 1.000000. mean reward 25.316751.\n",
      "World Perf: Episode 1216.000000. Reward 22.333333. action: 0.000000. mean reward 25.286917.\n",
      "World Perf: Episode 1219.000000. Reward 19.000000. action: 0.000000. mean reward 25.224047.\n",
      "World Perf: Episode 1222.000000. Reward 21.333333. action: 1.000000. mean reward 25.185140.\n",
      "World Perf: Episode 1225.000000. Reward 22.666667. action: 1.000000. mean reward 25.159956.\n",
      "World Perf: Episode 1228.000000. Reward 35.333333. action: 0.000000. mean reward 25.261689.\n",
      "World Perf: Episode 1231.000000. Reward 25.666667. action: 0.000000. mean reward 25.265739.\n",
      "World Perf: Episode 1234.000000. Reward 20.000000. action: 0.000000. mean reward 25.213082.\n",
      "World Perf: Episode 1237.000000. Reward 22.666667. action: 1.000000. mean reward 25.187618.\n",
      "World Perf: Episode 1240.000000. Reward 22.666667. action: 1.000000. mean reward 25.162408.\n",
      "World Perf: Episode 1243.000000. Reward 46.666667. action: 1.000000. mean reward 25.377451.\n",
      "World Perf: Episode 1246.000000. Reward 13.666667. action: 0.000000. mean reward 25.260343.\n",
      "World Perf: Episode 1249.000000. Reward 31.333333. action: 1.000000. mean reward 25.321073.\n",
      "World Perf: Episode 1252.000000. Reward 41.000000. action: 1.000000. mean reward 25.477862.\n",
      "World Perf: Episode 1255.000000. Reward 21.333333. action: 1.000000. mean reward 25.436417.\n",
      "World Perf: Episode 1258.000000. Reward 13.000000. action: 1.000000. mean reward 25.312053.\n",
      "World Perf: Episode 1261.000000. Reward 30.666667. action: 0.000000. mean reward 25.365599.\n",
      "World Perf: Episode 1264.000000. Reward 32.666667. action: 1.000000. mean reward 25.438609.\n",
      "World Perf: Episode 1267.000000. Reward 22.333333. action: 1.000000. mean reward 25.407557.\n",
      "World Perf: Episode 1270.000000. Reward 28.333333. action: 0.000000. mean reward 25.436814.\n",
      "World Perf: Episode 1273.000000. Reward 19.333333. action: 1.000000. mean reward 25.375780.\n",
      "World Perf: Episode 1276.000000. Reward 28.333333. action: 0.000000. mean reward 25.405355.\n",
      "World Perf: Episode 1279.000000. Reward 32.666667. action: 0.000000. mean reward 25.477968.\n",
      "World Perf: Episode 1282.000000. Reward 15.666667. action: 1.000000. mean reward 25.379855.\n",
      "World Perf: Episode 1285.000000. Reward 32.333333. action: 1.000000. mean reward 25.449390.\n",
      "World Perf: Episode 1288.000000. Reward 24.666667. action: 1.000000. mean reward 25.441563.\n",
      "World Perf: Episode 1291.000000. Reward 19.000000. action: 1.000000. mean reward 25.377147.\n",
      "World Perf: Episode 1294.000000. Reward 27.333333. action: 1.000000. mean reward 25.396709.\n",
      "World Perf: Episode 1297.000000. Reward 27.333333. action: 1.000000. mean reward 25.416075.\n",
      "World Perf: Episode 1300.000000. Reward 16.333333. action: 1.000000. mean reward 25.325248.\n",
      "World Perf: Episode 1303.000000. Reward 29.666667. action: 1.000000. mean reward 25.368662.\n",
      "World Perf: Episode 1306.000000. Reward 20.000000. action: 0.000000. mean reward 25.314975.\n",
      "World Perf: Episode 1309.000000. Reward 27.333333. action: 0.000000. mean reward 25.335159.\n",
      "World Perf: Episode 1312.000000. Reward 26.666667. action: 0.000000. mean reward 25.348474.\n",
      "World Perf: Episode 1315.000000. Reward 20.000000. action: 0.000000. mean reward 25.294989.\n",
      "World Perf: Episode 1318.000000. Reward 21.000000. action: 0.000000. mean reward 25.252039.\n",
      "World Perf: Episode 1321.000000. Reward 23.666667. action: 0.000000. mean reward 25.236186.\n",
      "World Perf: Episode 1324.000000. Reward 13.333333. action: 1.000000. mean reward 25.117157.\n",
      "World Perf: Episode 1327.000000. Reward 21.000000. action: 0.000000. mean reward 25.075986.\n",
      "World Perf: Episode 1330.000000. Reward 18.333333. action: 0.000000. mean reward 25.008559.\n",
      "World Perf: Episode 1333.000000. Reward 18.333333. action: 0.000000. mean reward 24.941807.\n",
      "World Perf: Episode 1336.000000. Reward 26.333333. action: 1.000000. mean reward 24.955722.\n",
      "World Perf: Episode 1339.000000. Reward 15.000000. action: 0.000000. mean reward 24.856165.\n",
      "World Perf: Episode 1342.000000. Reward 50.333333. action: 1.000000. mean reward 25.110937.\n",
      "World Perf: Episode 1345.000000. Reward 22.666667. action: 1.000000. mean reward 25.086494.\n",
      "World Perf: Episode 1348.000000. Reward 19.000000. action: 1.000000. mean reward 25.025629.\n",
      "World Perf: Episode 1351.000000. Reward 18.000000. action: 1.000000. mean reward 24.955373.\n",
      "World Perf: Episode 1354.000000. Reward 29.666667. action: 1.000000. mean reward 25.002486.\n",
      "World Perf: Episode 1357.000000. Reward 25.666667. action: 1.000000. mean reward 25.009127.\n",
      "World Perf: Episode 1360.000000. Reward 26.666667. action: 1.000000. mean reward 25.025703.\n",
      "World Perf: Episode 1363.000000. Reward 19.333333. action: 1.000000. mean reward 24.968779.\n",
      "World Perf: Episode 1366.000000. Reward 24.000000. action: 1.000000. mean reward 24.959091.\n",
      "World Perf: Episode 1369.000000. Reward 38.333333. action: 1.000000. mean reward 25.092834.\n",
      "World Perf: Episode 1372.000000. Reward 55.666667. action: 1.000000. mean reward 25.398572.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "World Perf: Episode 1375.000000. Reward 35.333333. action: 1.000000. mean reward 25.497920.\n",
      "World Perf: Episode 1378.000000. Reward 28.000000. action: 1.000000. mean reward 25.522940.\n",
      "World Perf: Episode 1381.000000. Reward 13.333333. action: 1.000000. mean reward 25.401044.\n",
      "World Perf: Episode 1384.000000. Reward 33.333333. action: 1.000000. mean reward 25.480367.\n",
      "World Perf: Episode 1387.000000. Reward 11.666667. action: 0.000000. mean reward 25.342230.\n",
      "World Perf: Episode 1390.000000. Reward 26.666667. action: 1.000000. mean reward 25.355475.\n",
      "World Perf: Episode 1393.000000. Reward 25.333333. action: 1.000000. mean reward 25.355253.\n",
      "World Perf: Episode 1396.000000. Reward 21.000000. action: 0.000000. mean reward 25.311701.\n",
      "World Perf: Episode 1399.000000. Reward 23.333333. action: 1.000000. mean reward 25.291917.\n",
      "World Perf: Episode 1402.000000. Reward 23.000000. action: 0.000000. mean reward 25.268998.\n",
      "World Perf: Episode 1405.000000. Reward 25.666667. action: 0.000000. mean reward 25.272974.\n",
      "World Perf: Episode 1408.000000. Reward 28.333333. action: 1.000000. mean reward 25.303578.\n",
      "World Perf: Episode 1411.000000. Reward 21.333333. action: 1.000000. mean reward 25.263876.\n",
      "World Perf: Episode 1414.000000. Reward 30.000000. action: 1.000000. mean reward 25.311237.\n",
      "World Perf: Episode 1417.000000. Reward 16.000000. action: 1.000000. mean reward 25.218125.\n",
      "World Perf: Episode 1420.000000. Reward 17.666667. action: 0.000000. mean reward 25.142610.\n",
      "World Perf: Episode 1423.000000. Reward 21.000000. action: 1.000000. mean reward 25.101184.\n",
      "World Perf: Episode 1426.000000. Reward 29.000000. action: 0.000000. mean reward 25.140172.\n",
      "World Perf: Episode 1429.000000. Reward 29.666667. action: 1.000000. mean reward 25.185437.\n",
      "World Perf: Episode 1432.000000. Reward 37.333333. action: 1.000000. mean reward 25.306916.\n",
      "World Perf: Episode 1435.000000. Reward 29.666667. action: 1.000000. mean reward 25.350513.\n",
      "World Perf: Episode 1438.000000. Reward 16.000000. action: 1.000000. mean reward 25.257008.\n",
      "World Perf: Episode 1441.000000. Reward 31.666667. action: 0.000000. mean reward 25.321105.\n",
      "World Perf: Episode 1444.000000. Reward 43.666667. action: 1.000000. mean reward 25.504560.\n",
      "World Perf: Episode 1447.000000. Reward 31.000000. action: 0.000000. mean reward 25.559515.\n",
      "World Perf: Episode 1450.000000. Reward 23.666667. action: 1.000000. mean reward 25.540586.\n",
      "World Perf: Episode 1453.000000. Reward 23.666667. action: 1.000000. mean reward 25.521847.\n",
      "World Perf: Episode 1456.000000. Reward 32.000000. action: 1.000000. mean reward 25.586629.\n",
      "World Perf: Episode 1459.000000. Reward 24.666667. action: 0.000000. mean reward 25.577429.\n",
      "World Perf: Episode 1462.000000. Reward 13.666667. action: 1.000000. mean reward 25.458321.\n",
      "World Perf: Episode 1465.000000. Reward 37.333333. action: 0.000000. mean reward 25.577072.\n",
      "World Perf: Episode 1468.000000. Reward 19.666667. action: 1.000000. mean reward 25.517968.\n",
      "World Perf: Episode 1471.000000. Reward 18.666667. action: 1.000000. mean reward 25.449455.\n",
      "World Perf: Episode 1474.000000. Reward 50.333333. action: 0.000000. mean reward 25.698293.\n",
      "World Perf: Episode 1477.000000. Reward 17.333333. action: 1.000000. mean reward 25.614644.\n",
      "World Perf: Episode 1480.000000. Reward 22.000000. action: 0.000000. mean reward 25.578497.\n",
      "World Perf: Episode 1483.000000. Reward 24.000000. action: 1.000000. mean reward 25.562712.\n",
      "World Perf: Episode 1486.000000. Reward 16.000000. action: 1.000000. mean reward 25.467085.\n",
      "World Perf: Episode 1489.000000. Reward 46.000000. action: 1.000000. mean reward 25.672414.\n",
      "World Perf: Episode 1492.000000. Reward 16.000000. action: 1.000000. mean reward 25.575690.\n",
      "World Perf: Episode 1495.000000. Reward 38.666667. action: 1.000000. mean reward 25.706600.\n",
      "World Perf: Episode 1498.000000. Reward 30.333333. action: 1.000000. mean reward 25.752867.\n",
      "World Perf: Episode 1501.000000. Reward 30.000000. action: 1.000000. mean reward 25.795339.\n",
      "World Perf: Episode 1504.000000. Reward 19.333333. action: 0.000000. mean reward 25.730719.\n",
      "World Perf: Episode 1507.000000. Reward 19.000000. action: 1.000000. mean reward 25.663411.\n",
      "World Perf: Episode 1510.000000. Reward 22.333333. action: 1.000000. mean reward 25.630111.\n",
      "World Perf: Episode 1513.000000. Reward 31.000000. action: 1.000000. mean reward 25.683810.\n",
      "World Perf: Episode 1516.000000. Reward 23.000000. action: 0.000000. mean reward 25.656971.\n",
      "World Perf: Episode 1519.000000. Reward 22.000000. action: 1.000000. mean reward 25.620402.\n",
      "World Perf: Episode 1522.000000. Reward 26.666667. action: 0.000000. mean reward 25.630864.\n",
      "World Perf: Episode 1525.000000. Reward 34.000000. action: 1.000000. mean reward 25.714556.\n",
      "World Perf: Episode 1528.000000. Reward 21.000000. action: 1.000000. mean reward 25.667410.\n",
      "World Perf: Episode 1531.000000. Reward 11.666667. action: 0.000000. mean reward 25.527403.\n",
      "World Perf: Episode 1534.000000. Reward 22.666667. action: 0.000000. mean reward 25.498795.\n",
      "World Perf: Episode 1537.000000. Reward 50.000000. action: 1.000000. mean reward 25.743807.\n",
      "World Perf: Episode 1540.000000. Reward 27.666667. action: 1.000000. mean reward 25.763036.\n",
      "World Perf: Episode 1543.000000. Reward 22.000000. action: 1.000000. mean reward 25.725406.\n",
      "World Perf: Episode 1546.000000. Reward 20.333333. action: 1.000000. mean reward 25.671485.\n",
      "World Perf: Episode 1549.000000. Reward 26.666667. action: 1.000000. mean reward 25.681437.\n",
      "World Perf: Episode 1552.000000. Reward 40.666667. action: 0.000000. mean reward 25.831289.\n",
      "World Perf: Episode 1555.000000. Reward 19.666667. action: 0.000000. mean reward 25.769643.\n",
      "World Perf: Episode 1558.000000. Reward 21.000000. action: 0.000000. mean reward 25.721946.\n",
      "World Perf: Episode 1561.000000. Reward 35.666667. action: 1.000000. mean reward 25.821394.\n",
      "World Perf: Episode 1564.000000. Reward 27.333333. action: 1.000000. mean reward 25.836513.\n",
      "World Perf: Episode 1567.000000. Reward 28.000000. action: 0.000000. mean reward 25.858148.\n",
      "World Perf: Episode 1570.000000. Reward 29.000000. action: 1.000000. mean reward 25.889566.\n",
      "World Perf: Episode 1573.000000. Reward 29.666667. action: 0.000000. mean reward 25.927337.\n",
      "World Perf: Episode 1576.000000. Reward 23.333333. action: 1.000000. mean reward 25.901397.\n",
      "World Perf: Episode 1579.000000. Reward 43.333333. action: 0.000000. mean reward 26.075717.\n",
      "World Perf: Episode 1582.000000. Reward 23.666667. action: 0.000000. mean reward 26.051626.\n",
      "World Perf: Episode 1585.000000. Reward 31.000000. action: 1.000000. mean reward 26.101110.\n",
      "World Perf: Episode 1588.000000. Reward 25.000000. action: 1.000000. mean reward 26.090099.\n",
      "World Perf: Episode 1591.000000. Reward 33.333333. action: 1.000000. mean reward 26.162531.\n",
      "World Perf: Episode 1594.000000. Reward 21.000000. action: 1.000000. mean reward 26.110906.\n",
      "World Perf: Episode 1597.000000. Reward 41.000000. action: 1.000000. mean reward 26.259797.\n",
      "World Perf: Episode 1600.000000. Reward 34.000000. action: 1.000000. mean reward 26.337199.\n",
      "World Perf: Episode 1603.000000. Reward 22.333333. action: 1.000000. mean reward 26.297160.\n",
      "World Perf: Episode 1606.000000. Reward 21.333333. action: 0.000000. mean reward 26.247522.\n",
      "World Perf: Episode 1609.000000. Reward 20.333333. action: 1.000000. mean reward 26.188380.\n",
      "World Perf: Episode 1612.000000. Reward 20.333333. action: 1.000000. mean reward 26.129830.\n",
      "World Perf: Episode 1615.000000. Reward 45.333333. action: 1.000000. mean reward 26.321865.\n",
      "World Perf: Episode 1618.000000. Reward 21.000000. action: 0.000000. mean reward 26.268646.\n",
      "World Perf: Episode 1621.000000. Reward 28.000000. action: 1.000000. mean reward 26.285959.\n",
      "World Perf: Episode 1624.000000. Reward 27.333333. action: 1.000000. mean reward 26.296433.\n",
      "World Perf: Episode 1627.000000. Reward 17.000000. action: 0.000000. mean reward 26.203469.\n",
      "World Perf: Episode 1630.000000. Reward 33.666667. action: 0.000000. mean reward 26.278101.\n",
      "World Perf: Episode 1633.000000. Reward 41.000000. action: 0.000000. mean reward 26.425320.\n",
      "World Perf: Episode 1636.000000. Reward 25.333333. action: 1.000000. mean reward 26.414400.\n",
      "World Perf: Episode 1639.000000. Reward 25.333333. action: 0.000000. mean reward 26.403589.\n",
      "World Perf: Episode 1642.000000. Reward 27.666667. action: 0.000000. mean reward 26.416220.\n",
      "World Perf: Episode 1645.000000. Reward 26.000000. action: 0.000000. mean reward 26.412058.\n",
      "World Perf: Episode 1648.000000. Reward 10.000000. action: 0.000000. mean reward 26.247937.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "World Perf: Episode 1651.000000. Reward 32.333333. action: 1.000000. mean reward 26.308791.\n",
      "World Perf: Episode 1654.000000. Reward 18.333333. action: 1.000000. mean reward 26.229037.\n",
      "World Perf: Episode 1657.000000. Reward 20.333333. action: 0.000000. mean reward 26.170080.\n",
      "World Perf: Episode 1660.000000. Reward 13.666667. action: 0.000000. mean reward 26.045046.\n",
      "World Perf: Episode 1663.000000. Reward 27.666667. action: 1.000000. mean reward 26.061262.\n",
      "World Perf: Episode 1666.000000. Reward 30.333333. action: 0.000000. mean reward 26.103982.\n",
      "World Perf: Episode 1669.000000. Reward 28.333333. action: 0.000000. mean reward 26.126276.\n",
      "World Perf: Episode 1672.000000. Reward 37.333333. action: 1.000000. mean reward 26.238347.\n",
      "World Perf: Episode 1675.000000. Reward 36.000000. action: 1.000000. mean reward 26.335963.\n",
      "World Perf: Episode 1678.000000. Reward 16.000000. action: 1.000000. mean reward 26.232603.\n",
      "World Perf: Episode 1681.000000. Reward 19.666667. action: 1.000000. mean reward 26.166944.\n",
      "World Perf: Episode 1684.000000. Reward 16.666667. action: 0.000000. mean reward 26.071941.\n",
      "World Perf: Episode 1687.000000. Reward 27.000000. action: 1.000000. mean reward 26.081222.\n",
      "World Perf: Episode 1690.000000. Reward 17.000000. action: 1.000000. mean reward 25.990410.\n",
      "World Perf: Episode 1693.000000. Reward 16.333333. action: 0.000000. mean reward 25.893839.\n",
      "World Perf: Episode 1696.000000. Reward 19.666667. action: 1.000000. mean reward 25.831567.\n",
      "World Perf: Episode 1699.000000. Reward 23.000000. action: 1.000000. mean reward 25.803252.\n",
      "World Perf: Episode 1702.000000. Reward 26.666667. action: 1.000000. mean reward 25.811886.\n",
      "World Perf: Episode 1705.000000. Reward 16.333333. action: 0.000000. mean reward 25.717100.\n",
      "World Perf: Episode 1708.000000. Reward 33.000000. action: 1.000000. mean reward 25.789929.\n",
      "World Perf: Episode 1711.000000. Reward 20.000000. action: 0.000000. mean reward 25.732030.\n",
      "World Perf: Episode 1714.000000. Reward 35.666667. action: 1.000000. mean reward 25.831376.\n",
      "World Perf: Episode 1717.000000. Reward 27.666667. action: 1.000000. mean reward 25.849729.\n",
      "World Perf: Episode 1720.000000. Reward 20.333333. action: 0.000000. mean reward 25.794565.\n",
      "World Perf: Episode 1723.000000. Reward 28.000000. action: 1.000000. mean reward 25.816620.\n",
      "World Perf: Episode 1726.000000. Reward 42.333333. action: 1.000000. mean reward 25.981787.\n",
      "World Perf: Episode 1729.000000. Reward 21.333333. action: 1.000000. mean reward 25.935302.\n",
      "World Perf: Episode 1732.000000. Reward 19.333333. action: 0.000000. mean reward 25.869282.\n",
      "World Perf: Episode 1735.000000. Reward 21.666667. action: 0.000000. mean reward 25.827256.\n",
      "World Perf: Episode 1738.000000. Reward 18.666667. action: 1.000000. mean reward 25.755650.\n",
      "World Perf: Episode 1741.000000. Reward 17.666667. action: 1.000000. mean reward 25.674761.\n",
      "World Perf: Episode 1744.000000. Reward 48.333333. action: 1.000000. mean reward 25.901346.\n",
      "World Perf: Episode 1747.000000. Reward 19.333333. action: 0.000000. mean reward 25.835666.\n",
      "World Perf: Episode 1750.000000. Reward 20.000000. action: 1.000000. mean reward 25.777309.\n",
      "World Perf: Episode 1753.000000. Reward 17.000000. action: 1.000000. mean reward 25.689536.\n",
      "World Perf: Episode 1756.000000. Reward 33.666667. action: 1.000000. mean reward 25.769308.\n",
      "World Perf: Episode 1759.000000. Reward 37.000000. action: 0.000000. mean reward 25.881615.\n",
      "World Perf: Episode 1762.000000. Reward 18.000000. action: 1.000000. mean reward 25.802798.\n",
      "World Perf: Episode 1765.000000. Reward 17.666667. action: 1.000000. mean reward 25.721437.\n",
      "World Perf: Episode 1768.000000. Reward 26.333333. action: 1.000000. mean reward 25.727556.\n",
      "World Perf: Episode 1771.000000. Reward 21.000000. action: 1.000000. mean reward 25.680281.\n",
      "World Perf: Episode 1774.000000. Reward 15.666667. action: 1.000000. mean reward 25.580144.\n",
      "World Perf: Episode 1777.000000. Reward 32.666667. action: 0.000000. mean reward 25.651010.\n",
      "World Perf: Episode 1780.000000. Reward 31.666667. action: 1.000000. mean reward 25.711166.\n",
      "World Perf: Episode 1783.000000. Reward 25.000000. action: 1.000000. mean reward 25.704055.\n",
      "World Perf: Episode 1786.000000. Reward 21.333333. action: 1.000000. mean reward 25.660347.\n",
      "World Perf: Episode 1789.000000. Reward 32.333333. action: 1.000000. mean reward 25.727077.\n",
      "World Perf: Episode 1792.000000. Reward 26.333333. action: 0.000000. mean reward 25.733140.\n",
      "World Perf: Episode 1795.000000. Reward 24.333333. action: 1.000000. mean reward 25.719142.\n",
      "World Perf: Episode 1798.000000. Reward 29.000000. action: 0.000000. mean reward 25.751950.\n",
      "World Perf: Episode 1801.000000. Reward 15.333333. action: 1.000000. mean reward 25.647764.\n",
      "World Perf: Episode 1804.000000. Reward 15.333333. action: 0.000000. mean reward 25.544620.\n",
      "World Perf: Episode 1807.000000. Reward 26.666667. action: 1.000000. mean reward 25.555840.\n",
      "World Perf: Episode 1810.000000. Reward 28.000000. action: 1.000000. mean reward 25.580282.\n",
      "World Perf: Episode 1813.000000. Reward 21.000000. action: 1.000000. mean reward 25.534479.\n",
      "World Perf: Episode 1816.000000. Reward 22.000000. action: 1.000000. mean reward 25.499134.\n",
      "World Perf: Episode 1819.000000. Reward 19.666667. action: 1.000000. mean reward 25.440810.\n",
      "World Perf: Episode 1822.000000. Reward 19.000000. action: 0.000000. mean reward 25.376401.\n",
      "World Perf: Episode 1825.000000. Reward 26.000000. action: 0.000000. mean reward 25.382637.\n",
      "World Perf: Episode 1828.000000. Reward 40.333333. action: 0.000000. mean reward 25.532144.\n",
      "World Perf: Episode 1831.000000. Reward 19.333333. action: 1.000000. mean reward 25.470156.\n",
      "World Perf: Episode 1834.000000. Reward 19.000000. action: 1.000000. mean reward 25.405455.\n",
      "World Perf: Episode 1837.000000. Reward 41.666667. action: 1.000000. mean reward 25.568067.\n",
      "World Perf: Episode 1840.000000. Reward 25.666667. action: 1.000000. mean reward 25.569053.\n",
      "World Perf: Episode 1843.000000. Reward 25.333333. action: 0.000000. mean reward 25.566696.\n",
      "World Perf: Episode 1846.000000. Reward 16.333333. action: 1.000000. mean reward 25.474362.\n",
      "World Perf: Episode 1849.000000. Reward 25.666667. action: 0.000000. mean reward 25.476285.\n",
      "World Perf: Episode 1852.000000. Reward 20.666667. action: 1.000000. mean reward 25.428189.\n",
      "World Perf: Episode 1855.000000. Reward 19.666667. action: 1.000000. mean reward 25.370574.\n",
      "World Perf: Episode 1858.000000. Reward 32.666667. action: 1.000000. mean reward 25.443535.\n",
      "World Perf: Episode 1861.000000. Reward 33.000000. action: 1.000000. mean reward 25.519099.\n",
      "World Perf: Episode 1864.000000. Reward 15.333333. action: 1.000000. mean reward 25.417242.\n",
      "World Perf: Episode 1867.000000. Reward 26.000000. action: 1.000000. mean reward 25.423069.\n",
      "World Perf: Episode 1870.000000. Reward 22.000000. action: 1.000000. mean reward 25.388839.\n",
      "World Perf: Episode 1873.000000. Reward 19.666667. action: 1.000000. mean reward 25.331617.\n",
      "World Perf: Episode 1876.000000. Reward 44.666667. action: 0.000000. mean reward 25.524967.\n",
      "World Perf: Episode 1879.000000. Reward 28.000000. action: 1.000000. mean reward 25.549718.\n",
      "World Perf: Episode 1882.000000. Reward 45.333333. action: 0.000000. mean reward 25.747554.\n",
      "World Perf: Episode 1885.000000. Reward 51.333333. action: 1.000000. mean reward 26.003412.\n",
      "World Perf: Episode 1888.000000. Reward 20.666667. action: 1.000000. mean reward 25.950044.\n",
      "World Perf: Episode 1891.000000. Reward 25.000000. action: 0.000000. mean reward 25.940544.\n",
      "World Perf: Episode 1894.000000. Reward 21.666667. action: 1.000000. mean reward 25.897805.\n",
      "World Perf: Episode 1897.000000. Reward 28.000000. action: 1.000000. mean reward 25.918827.\n",
      "World Perf: Episode 1900.000000. Reward 35.000000. action: 1.000000. mean reward 26.009639.\n",
      "World Perf: Episode 1903.000000. Reward 26.333333. action: 0.000000. mean reward 26.012876.\n",
      "World Perf: Episode 1906.000000. Reward 25.000000. action: 1.000000. mean reward 26.002747.\n",
      "World Perf: Episode 1909.000000. Reward 37.333333. action: 0.000000. mean reward 26.116053.\n",
      "World Perf: Episode 1912.000000. Reward 29.666667. action: 0.000000. mean reward 26.151559.\n",
      "World Perf: Episode 1915.000000. Reward 19.666667. action: 1.000000. mean reward 26.086710.\n",
      "World Perf: Episode 1918.000000. Reward 35.000000. action: 1.000000. mean reward 26.175843.\n",
      "World Perf: Episode 1921.000000. Reward 24.666667. action: 1.000000. mean reward 26.160751.\n",
      "World Perf: Episode 1924.000000. Reward 23.666667. action: 0.000000. mean reward 26.135810.\n",
      "World Perf: Episode 1927.000000. Reward 27.666667. action: 1.000000. mean reward 26.151119.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "World Perf: Episode 1930.000000. Reward 26.666667. action: 1.000000. mean reward 26.156274.\n",
      "World Perf: Episode 1933.000000. Reward 27.000000. action: 1.000000. mean reward 26.164711.\n",
      "World Perf: Episode 1936.000000. Reward 18.666667. action: 1.000000. mean reward 26.089731.\n",
      "World Perf: Episode 1939.000000. Reward 17.000000. action: 1.000000. mean reward 25.998834.\n",
      "World Perf: Episode 1942.000000. Reward 28.000000. action: 0.000000. mean reward 26.018845.\n",
      "World Perf: Episode 1945.000000. Reward 50.333333. action: 0.000000. mean reward 26.261990.\n",
      "World Perf: Episode 1948.000000. Reward 36.000000. action: 1.000000. mean reward 26.359370.\n",
      "World Perf: Episode 1951.000000. Reward 27.666667. action: 0.000000. mean reward 26.372443.\n",
      "World Perf: Episode 1954.000000. Reward 30.666667. action: 1.000000. mean reward 26.415386.\n",
      "World Perf: Episode 1957.000000. Reward 20.000000. action: 1.000000. mean reward 26.351232.\n",
      "World Perf: Episode 1960.000000. Reward 22.333333. action: 0.000000. mean reward 26.311053.\n",
      "World Perf: Episode 1963.000000. Reward 20.000000. action: 0.000000. mean reward 26.247942.\n",
      "World Perf: Episode 1966.000000. Reward 24.333333. action: 1.000000. mean reward 26.228796.\n",
      "World Perf: Episode 1969.000000. Reward 25.666667. action: 1.000000. mean reward 26.223175.\n",
      "World Perf: Episode 1972.000000. Reward 28.000000. action: 0.000000. mean reward 26.240943.\n",
      "World Perf: Episode 1975.000000. Reward 25.666667. action: 0.000000. mean reward 26.235200.\n",
      "World Perf: Episode 1978.000000. Reward 36.000000. action: 1.000000. mean reward 26.332848.\n",
      "World Perf: Episode 1981.000000. Reward 15.666667. action: 1.000000. mean reward 26.226186.\n",
      "World Perf: Episode 1984.000000. Reward 43.666667. action: 0.000000. mean reward 26.400591.\n",
      "World Perf: Episode 1987.000000. Reward 15.000000. action: 1.000000. mean reward 26.286585.\n",
      "World Perf: Episode 1990.000000. Reward 41.333333. action: 1.000000. mean reward 26.437053.\n",
      "World Perf: Episode 1993.000000. Reward 41.666667. action: 0.000000. mean reward 26.589349.\n",
      "World Perf: Episode 1996.000000. Reward 35.333333. action: 0.000000. mean reward 26.676789.\n",
      "World Perf: Episode 1999.000000. Reward 20.333333. action: 1.000000. mean reward 26.613354.\n",
      "World Perf: Episode 2002.000000. Reward 30.000000. action: 1.000000. mean reward 26.647221.\n",
      "World Perf: Episode 2005.000000. Reward 15.333333. action: 1.000000. mean reward 26.534082.\n",
      "World Perf: Episode 2008.000000. Reward 31.333333. action: 1.000000. mean reward 26.582074.\n",
      "World Perf: Episode 2011.000000. Reward 20.000000. action: 1.000000. mean reward 26.516254.\n",
      "World Perf: Episode 2014.000000. Reward 28.000000. action: 0.000000. mean reward 26.531091.\n",
      "World Perf: Episode 2017.000000. Reward 26.000000. action: 1.000000. mean reward 26.525780.\n",
      "World Perf: Episode 2020.000000. Reward 24.666667. action: 0.000000. mean reward 26.507189.\n",
      "World Perf: Episode 2023.000000. Reward 18.666667. action: 1.000000. mean reward 26.428784.\n",
      "World Perf: Episode 2026.000000. Reward 23.333333. action: 1.000000. mean reward 26.397829.\n",
      "World Perf: Episode 2029.000000. Reward 26.000000. action: 0.000000. mean reward 26.393851.\n",
      "World Perf: Episode 2032.000000. Reward 34.000000. action: 1.000000. mean reward 26.469912.\n",
      "World Perf: Episode 2035.000000. Reward 62.333333. action: 1.000000. mean reward 26.828547.\n",
      "World Perf: Episode 2038.000000. Reward 24.333333. action: 1.000000. mean reward 26.803595.\n",
      "World Perf: Episode 2041.000000. Reward 14.333333. action: 1.000000. mean reward 26.678892.\n",
      "World Perf: Episode 2044.000000. Reward 29.666667. action: 0.000000. mean reward 26.708770.\n",
      "World Perf: Episode 2047.000000. Reward 23.666667. action: 1.000000. mean reward 26.678349.\n",
      "World Perf: Episode 2050.000000. Reward 27.333333. action: 1.000000. mean reward 26.684899.\n",
      "World Perf: Episode 2053.000000. Reward 19.333333. action: 0.000000. mean reward 26.611383.\n",
      "World Perf: Episode 2056.000000. Reward 29.666667. action: 1.000000. mean reward 26.641936.\n",
      "World Perf: Episode 2059.000000. Reward 14.000000. action: 0.000000. mean reward 26.515516.\n",
      "World Perf: Episode 2062.000000. Reward 16.000000. action: 0.000000. mean reward 26.410361.\n",
      "World Perf: Episode 2065.000000. Reward 18.666667. action: 1.000000. mean reward 26.332924.\n",
      "World Perf: Episode 2068.000000. Reward 13.666667. action: 1.000000. mean reward 26.206262.\n",
      "World Perf: Episode 2071.000000. Reward 21.000000. action: 0.000000. mean reward 26.154199.\n",
      "World Perf: Episode 2074.000000. Reward 29.333333. action: 0.000000. mean reward 26.185990.\n",
      "World Perf: Episode 2077.000000. Reward 16.666667. action: 0.000000. mean reward 26.090797.\n",
      "World Perf: Episode 2080.000000. Reward 32.666667. action: 1.000000. mean reward 26.156556.\n",
      "World Perf: Episode 2083.000000. Reward 38.666667. action: 1.000000. mean reward 26.281657.\n",
      "World Perf: Episode 2086.000000. Reward 28.666667. action: 1.000000. mean reward 26.305507.\n",
      "World Perf: Episode 2089.000000. Reward 18.666667. action: 0.000000. mean reward 26.229119.\n",
      "World Perf: Episode 2092.000000. Reward 35.000000. action: 0.000000. mean reward 26.316827.\n",
      "World Perf: Episode 2095.000000. Reward 28.666667. action: 1.000000. mean reward 26.340326.\n",
      "World Perf: Episode 2098.000000. Reward 22.000000. action: 1.000000. mean reward 26.296923.\n",
      "World Perf: Episode 2101.000000. Reward 14.000000. action: 1.000000. mean reward 26.173953.\n",
      "World Perf: Episode 2104.000000. Reward 25.333333. action: 1.000000. mean reward 26.165547.\n",
      "World Perf: Episode 2107.000000. Reward 31.000000. action: 1.000000. mean reward 26.213892.\n",
      "World Perf: Episode 2110.000000. Reward 17.000000. action: 0.000000. mean reward 26.121753.\n",
      "World Perf: Episode 2113.000000. Reward 21.333333. action: 1.000000. mean reward 26.073869.\n",
      "World Perf: Episode 2116.000000. Reward 20.333333. action: 1.000000. mean reward 26.016463.\n",
      "World Perf: Episode 2119.000000. Reward 21.000000. action: 1.000000. mean reward 25.966299.\n",
      "World Perf: Episode 2122.000000. Reward 25.333333. action: 1.000000. mean reward 25.959969.\n",
      "World Perf: Episode 2125.000000. Reward 29.666667. action: 0.000000. mean reward 25.997036.\n",
      "World Perf: Episode 2128.000000. Reward 24.000000. action: 0.000000. mean reward 25.977066.\n",
      "World Perf: Episode 2131.000000. Reward 21.333333. action: 1.000000. mean reward 25.930628.\n",
      "World Perf: Episode 2134.000000. Reward 25.333333. action: 1.000000. mean reward 25.924655.\n",
      "World Perf: Episode 2137.000000. Reward 32.000000. action: 1.000000. mean reward 25.985409.\n",
      "World Perf: Episode 2140.000000. Reward 17.000000. action: 1.000000. mean reward 25.895555.\n",
      "World Perf: Episode 2143.000000. Reward 32.000000. action: 1.000000. mean reward 25.956599.\n",
      "World Perf: Episode 2146.000000. Reward 20.666667. action: 1.000000. mean reward 25.903700.\n",
      "World Perf: Episode 2149.000000. Reward 37.000000. action: 1.000000. mean reward 26.014663.\n",
      "World Perf: Episode 2152.000000. Reward 22.000000. action: 0.000000. mean reward 25.974516.\n",
      "World Perf: Episode 2155.000000. Reward 24.666667. action: 1.000000. mean reward 25.961438.\n",
      "World Perf: Episode 2158.000000. Reward 15.333333. action: 0.000000. mean reward 25.855157.\n",
      "World Perf: Episode 2161.000000. Reward 24.000000. action: 1.000000. mean reward 25.836605.\n",
      "World Perf: Episode 2164.000000. Reward 36.333333. action: 0.000000. mean reward 25.941572.\n",
      "World Perf: Episode 2167.000000. Reward 25.000000. action: 1.000000. mean reward 25.932157.\n",
      "World Perf: Episode 2170.000000. Reward 33.333333. action: 1.000000. mean reward 26.006168.\n",
      "World Perf: Episode 2173.000000. Reward 26.333333. action: 1.000000. mean reward 26.009440.\n",
      "World Perf: Episode 2176.000000. Reward 29.333333. action: 1.000000. mean reward 26.042679.\n",
      "World Perf: Episode 2179.000000. Reward 22.000000. action: 1.000000. mean reward 26.002252.\n",
      "World Perf: Episode 2182.000000. Reward 16.333333. action: 1.000000. mean reward 25.905563.\n",
      "World Perf: Episode 2185.000000. Reward 22.333333. action: 0.000000. mean reward 25.869841.\n",
      "World Perf: Episode 2188.000000. Reward 36.666667. action: 1.000000. mean reward 25.977809.\n",
      "World Perf: Episode 2191.000000. Reward 34.000000. action: 1.000000. mean reward 26.058031.\n",
      "World Perf: Episode 2194.000000. Reward 12.333333. action: 1.000000. mean reward 25.920784.\n",
      "World Perf: Episode 2197.000000. Reward 26.333333. action: 1.000000. mean reward 25.924909.\n",
      "World Perf: Episode 2200.000000. Reward 26.333333. action: 1.000000. mean reward 25.928994.\n",
      "World Perf: Episode 2203.000000. Reward 25.333333. action: 1.000000. mean reward 25.923037.\n",
      "World Perf: Episode 2206.000000. Reward 28.000000. action: 1.000000. mean reward 25.943807.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "World Perf: Episode 2209.000000. Reward 43.666667. action: 1.000000. mean reward 26.121035.\n",
      "World Perf: Episode 2212.000000. Reward 27.000000. action: 1.000000. mean reward 26.129825.\n",
      "World Perf: Episode 2215.000000. Reward 17.666667. action: 1.000000. mean reward 26.045193.\n",
      "World Perf: Episode 2218.000000. Reward 22.666667. action: 0.000000. mean reward 26.011408.\n",
      "World Perf: Episode 2221.000000. Reward 20.000000. action: 0.000000. mean reward 25.951294.\n",
      "World Perf: Episode 2224.000000. Reward 23.000000. action: 1.000000. mean reward 25.921781.\n",
      "World Perf: Episode 2227.000000. Reward 33.666667. action: 1.000000. mean reward 25.999230.\n",
      "World Perf: Episode 2230.000000. Reward 49.333333. action: 0.000000. mean reward 26.232571.\n",
      "World Perf: Episode 2233.000000. Reward 21.666667. action: 1.000000. mean reward 26.186912.\n",
      "World Perf: Episode 2236.000000. Reward 17.000000. action: 1.000000. mean reward 26.095043.\n",
      "World Perf: Episode 2239.000000. Reward 26.333333. action: 1.000000. mean reward 26.097426.\n",
      "World Perf: Episode 2242.000000. Reward 31.000000. action: 0.000000. mean reward 26.146451.\n",
      "World Perf: Episode 2245.000000. Reward 32.000000. action: 0.000000. mean reward 26.204987.\n",
      "World Perf: Episode 2248.000000. Reward 19.333333. action: 1.000000. mean reward 26.136270.\n",
      "World Perf: Episode 2251.000000. Reward 38.666667. action: 0.000000. mean reward 26.261574.\n",
      "World Perf: Episode 2254.000000. Reward 36.333333. action: 1.000000. mean reward 26.362292.\n",
      "World Perf: Episode 2257.000000. Reward 28.333333. action: 0.000000. mean reward 26.382002.\n",
      "World Perf: Episode 2260.000000. Reward 23.333333. action: 1.000000. mean reward 26.351516.\n",
      "World Perf: Episode 2263.000000. Reward 18.666667. action: 0.000000. mean reward 26.274667.\n",
      "World Perf: Episode 2266.000000. Reward 29.333333. action: 1.000000. mean reward 26.305254.\n",
      "World Perf: Episode 2269.000000. Reward 27.000000. action: 0.000000. mean reward 26.312201.\n",
      "World Perf: Episode 2272.000000. Reward 16.000000. action: 1.000000. mean reward 26.209079.\n",
      "World Perf: Episode 2275.000000. Reward 37.666667. action: 0.000000. mean reward 26.323655.\n",
      "World Perf: Episode 2278.000000. Reward 26.000000. action: 0.000000. mean reward 26.320419.\n",
      "World Perf: Episode 2281.000000. Reward 32.000000. action: 1.000000. mean reward 26.377214.\n",
      "World Perf: Episode 2284.000000. Reward 31.333333. action: 1.000000. mean reward 26.426776.\n",
      "World Perf: Episode 2287.000000. Reward 14.666667. action: 0.000000. mean reward 26.309174.\n",
      "World Perf: Episode 2290.000000. Reward 25.333333. action: 1.000000. mean reward 26.299416.\n",
      "World Perf: Episode 2293.000000. Reward 25.666667. action: 1.000000. mean reward 26.293089.\n",
      "World Perf: Episode 2296.000000. Reward 14.000000. action: 1.000000. mean reward 26.170158.\n",
      "World Perf: Episode 2299.000000. Reward 14.000000. action: 1.000000. mean reward 26.048456.\n",
      "World Perf: Episode 2302.000000. Reward 26.000000. action: 1.000000. mean reward 26.047972.\n",
      "World Perf: Episode 2305.000000. Reward 29.000000. action: 0.000000. mean reward 26.077492.\n",
      "World Perf: Episode 2308.000000. Reward 28.000000. action: 0.000000. mean reward 26.096717.\n",
      "World Perf: Episode 2311.000000. Reward 40.333333. action: 1.000000. mean reward 26.239083.\n",
      "World Perf: Episode 2314.000000. Reward 23.000000. action: 1.000000. mean reward 26.206692.\n",
      "World Perf: Episode 2317.000000. Reward 16.666667. action: 1.000000. mean reward 26.111292.\n",
      "World Perf: Episode 2320.000000. Reward 47.666667. action: 1.000000. mean reward 26.326846.\n",
      "World Perf: Episode 2323.000000. Reward 18.666667. action: 0.000000. mean reward 26.250244.\n",
      "World Perf: Episode 2326.000000. Reward 18.666667. action: 1.000000. mean reward 26.174408.\n",
      "World Perf: Episode 2329.000000. Reward 14.333333. action: 0.000000. mean reward 26.055997.\n",
      "World Perf: Episode 2332.000000. Reward 21.666667. action: 1.000000. mean reward 26.012104.\n",
      "World Perf: Episode 2335.000000. Reward 43.666667. action: 1.000000. mean reward 26.188650.\n",
      "World Perf: Episode 2338.000000. Reward 25.000000. action: 0.000000. mean reward 26.176763.\n",
      "World Perf: Episode 2341.000000. Reward 32.333333. action: 1.000000. mean reward 26.238329.\n",
      "World Perf: Episode 2344.000000. Reward 17.333333. action: 1.000000. mean reward 26.149279.\n",
      "World Perf: Episode 2347.000000. Reward 20.333333. action: 1.000000. mean reward 26.091120.\n",
      "World Perf: Episode 2350.000000. Reward 27.333333. action: 0.000000. mean reward 26.103542.\n",
      "World Perf: Episode 2353.000000. Reward 32.666667. action: 1.000000. mean reward 26.169173.\n",
      "World Perf: Episode 2356.000000. Reward 40.666667. action: 1.000000. mean reward 26.314148.\n",
      "World Perf: Episode 2359.000000. Reward 32.000000. action: 0.000000. mean reward 26.371006.\n",
      "World Perf: Episode 2362.000000. Reward 10.000000. action: 1.000000. mean reward 26.207296.\n",
      "World Perf: Episode 2365.000000. Reward 26.333333. action: 1.000000. mean reward 26.208557.\n",
      "World Perf: Episode 2368.000000. Reward 18.000000. action: 1.000000. mean reward 26.126471.\n",
      "World Perf: Episode 2371.000000. Reward 26.666667. action: 0.000000. mean reward 26.131873.\n",
      "World Perf: Episode 2374.000000. Reward 14.000000. action: 1.000000. mean reward 26.010554.\n",
      "World Perf: Episode 2377.000000. Reward 23.000000. action: 0.000000. mean reward 25.980449.\n",
      "World Perf: Episode 2380.000000. Reward 25.000000. action: 0.000000. mean reward 25.970644.\n",
      "World Perf: Episode 2383.000000. Reward 21.333333. action: 0.000000. mean reward 25.924271.\n",
      "World Perf: Episode 2386.000000. Reward 39.666667. action: 0.000000. mean reward 26.061695.\n",
      "World Perf: Episode 2389.000000. Reward 15.000000. action: 1.000000. mean reward 25.951078.\n",
      "World Perf: Episode 2392.000000. Reward 33.333333. action: 1.000000. mean reward 26.024901.\n",
      "World Perf: Episode 2395.000000. Reward 14.000000. action: 1.000000. mean reward 25.904652.\n",
      "World Perf: Episode 2398.000000. Reward 26.666667. action: 1.000000. mean reward 25.912272.\n",
      "World Perf: Episode 2401.000000. Reward 30.000000. action: 1.000000. mean reward 25.953149.\n",
      "World Perf: Episode 2404.000000. Reward 25.000000. action: 1.000000. mean reward 25.943618.\n",
      "World Perf: Episode 2407.000000. Reward 37.000000. action: 1.000000. mean reward 26.054182.\n",
      "World Perf: Episode 2410.000000. Reward 31.333333. action: 1.000000. mean reward 26.106973.\n",
      "World Perf: Episode 2413.000000. Reward 33.666667. action: 1.000000. mean reward 26.182570.\n",
      "World Perf: Episode 2416.000000. Reward 34.333333. action: 0.000000. mean reward 26.264078.\n",
      "World Perf: Episode 2419.000000. Reward 20.000000. action: 1.000000. mean reward 26.201437.\n",
      "World Perf: Episode 2422.000000. Reward 15.666667. action: 1.000000. mean reward 26.096089.\n",
      "World Perf: Episode 2425.000000. Reward 56.000000. action: 0.000000. mean reward 26.395128.\n",
      "World Perf: Episode 2428.000000. Reward 26.666667. action: 0.000000. mean reward 26.397844.\n",
      "World Perf: Episode 2431.000000. Reward 24.666667. action: 1.000000. mean reward 26.380532.\n",
      "World Perf: Episode 2434.000000. Reward 31.000000. action: 1.000000. mean reward 26.426727.\n",
      "World Perf: Episode 2437.000000. Reward 29.666667. action: 0.000000. mean reward 26.459126.\n",
      "World Perf: Episode 2440.000000. Reward 25.333333. action: 0.000000. mean reward 26.447868.\n",
      "World Perf: Episode 2443.000000. Reward 42.000000. action: 0.000000. mean reward 26.603389.\n",
      "World Perf: Episode 2446.000000. Reward 21.000000. action: 0.000000. mean reward 26.547355.\n",
      "World Perf: Episode 2449.000000. Reward 13.333333. action: 1.000000. mean reward 26.415215.\n",
      "World Perf: Episode 2452.000000. Reward 27.000000. action: 0.000000. mean reward 26.421063.\n",
      "World Perf: Episode 2455.000000. Reward 16.333333. action: 0.000000. mean reward 26.320186.\n",
      "World Perf: Episode 2458.000000. Reward 21.000000. action: 0.000000. mean reward 26.266984.\n",
      "World Perf: Episode 2461.000000. Reward 18.333333. action: 1.000000. mean reward 26.187647.\n",
      "World Perf: Episode 2464.000000. Reward 21.333333. action: 1.000000. mean reward 26.139104.\n",
      "World Perf: Episode 2467.000000. Reward 21.000000. action: 1.000000. mean reward 26.087713.\n",
      "World Perf: Episode 2470.000000. Reward 34.000000. action: 1.000000. mean reward 26.166836.\n",
      "World Perf: Episode 2473.000000. Reward 33.333333. action: 0.000000. mean reward 26.238501.\n",
      "World Perf: Episode 2476.000000. Reward 25.333333. action: 1.000000. mean reward 26.229449.\n",
      "World Perf: Episode 2479.000000. Reward 31.000000. action: 1.000000. mean reward 26.277155.\n",
      "World Perf: Episode 2482.000000. Reward 25.000000. action: 1.000000. mean reward 26.264383.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "World Perf: Episode 2485.000000. Reward 43.333333. action: 1.000000. mean reward 26.435073.\n",
      "World Perf: Episode 2488.000000. Reward 25.333333. action: 1.000000. mean reward 26.424055.\n",
      "World Perf: Episode 2491.000000. Reward 15.333333. action: 1.000000. mean reward 26.313148.\n",
      "World Perf: Episode 2494.000000. Reward 32.333333. action: 0.000000. mean reward 26.373350.\n",
      "World Perf: Episode 2497.000000. Reward 35.666667. action: 0.000000. mean reward 26.466283.\n",
      "World Perf: Episode 2500.000000. Reward 34.666667. action: 1.000000. mean reward 26.548287.\n",
      "World Perf: Episode 2503.000000. Reward 30.666667. action: 1.000000. mean reward 26.589471.\n",
      "World Perf: Episode 2506.000000. Reward 32.666667. action: 1.000000. mean reward 26.650243.\n",
      "World Perf: Episode 2509.000000. Reward 15.000000. action: 1.000000. mean reward 26.533740.\n",
      "World Perf: Episode 2512.000000. Reward 16.666667. action: 0.000000. mean reward 26.435070.\n",
      "World Perf: Episode 2515.000000. Reward 40.333333. action: 1.000000. mean reward 26.574052.\n",
      "World Perf: Episode 2518.000000. Reward 28.000000. action: 0.000000. mean reward 26.588312.\n",
      "World Perf: Episode 2521.000000. Reward 30.666667. action: 1.000000. mean reward 26.629095.\n",
      "World Perf: Episode 2524.000000. Reward 38.333333. action: 0.000000. mean reward 26.746138.\n",
      "World Perf: Episode 2527.000000. Reward 31.333333. action: 0.000000. mean reward 26.792010.\n",
      "World Perf: Episode 2530.000000. Reward 15.000000. action: 1.000000. mean reward 26.674090.\n",
      "World Perf: Episode 2533.000000. Reward 22.333333. action: 0.000000. mean reward 26.630682.\n",
      "World Perf: Episode 2536.000000. Reward 29.000000. action: 1.000000. mean reward 26.654375.\n",
      "World Perf: Episode 2539.000000. Reward 20.000000. action: 0.000000. mean reward 26.587831.\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-9-ab77c48e6b1d>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     29\u001b[0m         \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobservation\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m4\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     30\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 31\u001b[1;33m         \u001b[0mtfprob\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msess\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mprobability\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mfeed_dict\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m{\u001b[0m\u001b[0mobservations\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     32\u001b[0m         \u001b[0maction\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m1\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0muniform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m<\u001b[0m \u001b[0mtfprob\u001b[0m \u001b[1;32melse\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     33\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\yluaw\\Downloads\\shaoyu\\python-3.5.3.amd64\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36mrun\u001b[1;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m    776\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    777\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[1;32m--> 778\u001b[1;33m                          run_metadata_ptr)\n\u001b[0m\u001b[0;32m    779\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    780\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\yluaw\\Downloads\\shaoyu\\python-3.5.3.amd64\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run\u001b[1;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m    980\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    981\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[1;32m--> 982\u001b[1;33m                              feed_dict_string, options, run_metadata)\n\u001b[0m\u001b[0;32m    983\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    984\u001b[0m       \u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\yluaw\\Downloads\\shaoyu\\python-3.5.3.amd64\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_run\u001b[1;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1030\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1031\u001b[0m       return self._do_call(_run_fn, self._session, feed_dict, fetch_list,\n\u001b[1;32m-> 1032\u001b[1;33m                            target_list, options, run_metadata)\n\u001b[0m\u001b[0;32m   1033\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1034\u001b[0m       return self._do_call(_prun_fn, self._session, handle, feed_dict,\n",
      "\u001b[1;32mC:\\Users\\yluaw\\Downloads\\shaoyu\\python-3.5.3.amd64\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_call\u001b[1;34m(self, fn, *args)\u001b[0m\n\u001b[0;32m   1037\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1038\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1039\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1040\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1041\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\yluaw\\Downloads\\shaoyu\\python-3.5.3.amd64\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[1;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[0;32m   1019\u001b[0m         return tf_session.TF_Run(session, options,\n\u001b[0;32m   1020\u001b[0m                                  \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1021\u001b[1;33m                                  status, run_metadata)\n\u001b[0m\u001b[0;32m   1022\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1023\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msession\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "xs,drs,ys,ds = [],[],[],[]\n",
    "running_reward = None\n",
    "reward_sum = 0\n",
    "episode_number = 1\n",
    "real_episodes = 1\n",
    "init = tf.global_variables_initializer()\n",
    "batch_size = real_bs\n",
    "\n",
    "drawFromModel = False # When set to True, will use model for observations\n",
    "trainTheModel = True # Whether to train the model\n",
    "trainThePolicy = False # Whether to train the policy\n",
    "switch_point = 1\n",
    "\n",
    "# Launch the graph\n",
    "with tf.Session() as sess:\n",
    "    rendering = False\n",
    "    sess.run(init)\n",
    "    observation = env.reset()\n",
    "    x = observation\n",
    "    gradBuffer = sess.run(tvars)\n",
    "    gradBuffer = resetGradBuffer(gradBuffer)\n",
    "    \n",
    "    while episode_number <= 5000:\n",
    "        # Start displaying environment once performance is acceptably high.\n",
    "        if (reward_sum/batch_size > 150 and drawFromModel == False) or rendering == True : \n",
    "            env.render()\n",
    "            rendering = True\n",
    "            \n",
    "        x = np.reshape(observation,[1,4])\n",
    "\n",
    "        tfprob = sess.run(probability,feed_dict={observations: x})\n",
    "        action = 1 if np.random.uniform() < tfprob else 0\n",
    "\n",
    "        # record various intermediates (needed later for backprop)\n",
    "        xs.append(x) \n",
    "        y = 1 if action == 0 else 0 \n",
    "        ys.append(y)\n",
    "        \n",
    "        # step the  model or real environment and get new measurements\n",
    "        if drawFromModel == False:\n",
    "            observation, reward, done, info = env.step(action)\n",
    "        else:\n",
    "            observation, reward, done = stepModel(sess,xs,action)\n",
    "                \n",
    "        reward_sum += reward\n",
    "        \n",
    "        ds.append(done*1)\n",
    "        drs.append(reward) # record reward (has to be done after we call step() to get reward for previous action)\n",
    "\n",
    "        if done: \n",
    "            \n",
    "            if drawFromModel == False: \n",
    "                real_episodes += 1\n",
    "            episode_number += 1\n",
    "\n",
    "            # stack together all inputs, hidden states, action gradients, and rewards for this episode\n",
    "            epx = np.vstack(xs)\n",
    "            epy = np.vstack(ys)\n",
    "            epr = np.vstack(drs)\n",
    "            epd = np.vstack(ds)\n",
    "            xs,drs,ys,ds = [],[],[],[] # reset array memory\n",
    "            \n",
    "            if trainTheModel == True:\n",
    "                \n",
    "                ################################################################################\n",
    "                # TODO: Implement training of the mode                                         #\n",
    "                ################################################################################\n",
    "                pass\n",
    "                ################################################################################\n",
    "                #                                 END OF YOUR CODE                             #\n",
    "                ################################################################################\n",
    "                \n",
    "\n",
    "            if trainThePolicy == True:\n",
    "                \n",
    "                ################################################################################\n",
    "                # TODO: Implement training of the policy                                       #\n",
    "                ################################################################################\n",
    "                pass\n",
    "                ################################################################################\n",
    "                #                                 END OF YOUR CODE                             #\n",
    "                ################################################################################\n",
    "                \n",
    "                # If gradients becom too large, end training process\n",
    "                if np.sum(tGrad[0] == tGrad[0]) == 0:\n",
    "                    break\n",
    "                for ix,grad in enumerate(tGrad):\n",
    "                    gradBuffer[ix] += grad\n",
    "                \n",
    "            if switch_point + batch_size == episode_number: \n",
    "                switch_point = episode_number\n",
    "                if trainThePolicy == True:\n",
    "                    sess.run(updateGrads,feed_dict={W1Grad: gradBuffer[0],W2Grad:gradBuffer[1]})\n",
    "                    gradBuffer = resetGradBuffer(gradBuffer)\n",
    "\n",
    "                running_reward = reward_sum if running_reward is None else running_reward * 0.99 + reward_sum * 0.01\n",
    "                if drawFromModel == False:\n",
    "                    print('World Perf: Episode %f. Reward %f. action: %f. mean reward %f.' % (real_episodes,reward_sum/real_bs,action, running_reward/real_bs))\n",
    "                    if reward_sum/batch_size > 200:\n",
    "                        break\n",
    "                reward_sum = 0\n",
    "\n",
    "                # Once the model has been trained on 100 episodes\n",
    "                if episode_number > 100:\n",
    "                    \n",
    "                    ################################################################################\n",
    "                    # TODO: Alternating between training the policy from the model and training    #\n",
    "                    # the model from the real environment.                                         #\n",
    "                    ################################################################################\n",
    "                    pass\n",
    "                    ################################################################################\n",
    "                    #                                 END OF YOUR CODE                             #\n",
    "                    ################################################################################\n",
    "            \n",
    "            if drawFromModel == True:\n",
    "                observation = np.random.uniform(-0.1,0.1,[4]) # Generate reasonable starting point\n",
    "                batch_size = model_bs\n",
    "            else:\n",
    "                observation = env.reset()\n",
    "                batch_size = real_bs\n",
    "                \n",
    "print(real_episodes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Checking model representation\n",
    "Here we can examine how well the model is able to approximate the true environment after training. The green line indicates the real environment, and the blue indicates model predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'pState' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-11-ddaebfb147e0>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m6\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m     \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msubplot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m6\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mi\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m     \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpState\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m     \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msubplot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m6\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m     \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstate_nextsAll\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'pState' is not defined"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP4AAACACAYAAAArvtTgAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1ff1abb1a90>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(8, 12))\n",
    "for i in range(6):\n",
    "    plt.subplot(6, 2, 2*i + 1)\n",
    "    plt.plot(pState[:,i])\n",
    "    plt.subplot(6,2,2*i+1)\n",
    "    plt.plot(state_nextsAll[:,i])\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
