{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Basic Q-Learning Algorithms\n",
    "In this exercise we are going be exploring a family of RL algorithms called Q-Learning algorithms. You will begin by implementing a simple lookup-table version of the algorithm, and then a neural-network equivalent using Tensorflow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## OpenAI Gym Environment\n",
    "For this exercise we will use the [FrozenLake](https://gym.openai.com/envs/FrozenLake-v0) environment from the [OpenAI gym](https://gym.openai.com) as a toy example. For those unfamiliar, the OpenAI gym provides an easy way for people to experiment with their learning agents in an array of provided toy games. The FrozenLake environment consists of a `4 x 4` grid of blocks, each one either being the start block `S`, the goal block `G`, a safe frozen block `F`, or a dangerous hole `H`. The objective is to have an agent learn to navigate from the start to the goal without moving onto a hole. At any given time the agent can choose to move either up, down, left, or right. The catch is that there is a wind which occasionally blows the agent onto a space they didn’t choose. As such, perfect performance every time is impossible, but learning to avoid the holes and reach the goal are certainly still doable. The reward at every step is 0, except for entering the goal, which provides a reward of 1. Thus, we will need an algorithm that learns long-term expected rewards. This is exactly what Q-Learning is designed to provide."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Install OpenAI Gym\n",
    "To install the OpenAI gym, simply use  `pip install gym`  to grab it."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import gym\n",
    "env = gym.make('FrozenLake-v0')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For more information, please refer to [OpenAI documentation](https://gym.openai.com/docs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1 - Q-Table learning algorithm\n",
    "In it’s simplest implementation, Q-Learning is a table of values for every state (row) and action (column) possible in the environment. Within each cell of the table, we learn a value for how good it is to take a given action within a given state. In the case of the FrozenLake environment, we have 16 possible states (one for each block), and 4 possible actions (the four directions of movement), giving us a 16 x 4 table of Q-values. We start by initializing the table to be uniform (all zeros), and then as we observe the rewards we obtain for various actions, we update the table accordingly.\n",
    "\n",
    "We make updates to our Q-table using something called the [Bellman equation](https://en.wikipedia.org/wiki/Bellman_equation), which states that the expected long-term reward for a given action is equal to the immediate reward from the current action combined with the expected reward from the best future action taken at the following state. In equation form, the rule looks like this (Equation 1):\n",
    "$$ Q(s,a) = r + γ(\\max(Q(s’,a’)) $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This says that the Q-value for a given state ($s$) and action ($a$) should represent the current reward ($r$) plus the maximum discounted ($\\lambda$) future reward expected according to our own table for the next state ($s'$) we would end up in."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Initialize table, with states as rows and actions (up, down, left, or right) as columns \n",
    "Q = np.zeros([env.observation_space.n,env.action_space.n])\n",
    "#Set learning parameters\n",
    "lr = .8\n",
    "#Set discounted factor\n",
    "y = .95\n",
    "num_episodes = 2000\n",
    "#create lists to contain total rewards and steps per episode\n",
    "rList = []\n",
    "for i in range(num_episodes):\n",
    "    #Reset environment and get first new observation\n",
    "    s = env.reset()\n",
    "    \n",
    "    #Total reward in one episode\n",
    "    rAll = 0\n",
    "    d = False\n",
    "    j = 0\n",
    "    while j < 99:\n",
    "        j+=1\n",
    "        ###############################################################################\n",
    "        # TODO: Implement the Q-Table learning algorithm.                             #\n",
    "        # You will need to do the following:                                          #\n",
    "        # (1) Choose an action by greedily (with noise) picking from Q table given s  #\n",
    "        #     as input.                                                               #\n",
    "        # (2) Get new state s1, reward r and done d from environment                  #\n",
    "        # (3) Update Q-Table with new knowledge.                                      #\n",
    "        # (4) Cumulate the total reward rAll                                          #\n",
    "        # (5) Update s                                                                #\n",
    "        # Note: You may use the gym interfaces env.action_space, env.step etc.        #\n",
    "        #       E.g. observation, reward, done, info = env.step(action)               #\n",
    "        #       Please refer to the docs for more information.                        #\n",
    "        #       For (1), consider adding noise as a mean of encouraging exploration.  #\n",
    "        #       For (3), calculate the new target Q-value using Bellman equation.     #\n",
    "        #       Instead of directly updating toward it, we take a small step in the   #\n",
    "        #       direction that will make the Q value closer to the target, i.e. use   #\n",
    "        #       learning rate that controls how much of the difference between        #\n",
    "        #       newly proposed Q-value and previous Q-value                           #\n",
    "        ###############################################################################\n",
    "        action = np.argmax(Q[s,:] + np.random.randn(1, 4)/(i + 1))\n",
    "        s1, r, d, _ = env.step(action)\n",
    "        Q[s, action] += lr * (r + y * np.max(Q[s1, :]) - Q[s, action])\n",
    "        rAll += r\n",
    "        s = s1\n",
    "        ##############################################################################\n",
    "        #                             END OF YOUR CODE                               #\n",
    "        ##############################################################################\n",
    "        \n",
    "        #end of one episode\n",
    "        if d == True:\n",
    "            break\n",
    "    rList.append(rAll)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The score is around 0.5 after 2000 episodes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score over time: 0.657\n"
     ]
    }
   ],
   "source": [
    "print(\"Score over time: \" +  str(sum(rList)/num_episodes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final Q-Table Values\n",
      "[[  1.14082326e-01   1.14682927e-02   1.40460620e-02   1.42592482e-02]\n",
      " [  3.27286370e-03   2.70687549e-05   0.00000000e+00   1.88318628e-01]\n",
      " [  2.28340457e-03   8.42718605e-03   2.08912031e-03   1.23679311e-01]\n",
      " [  7.82853425e-04   0.00000000e+00   1.93881694e-03   9.15074604e-02]\n",
      " [  2.46571285e-01   3.84665821e-03   3.31935637e-03   3.46460331e-03]\n",
      " [  0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00]\n",
      " [  2.96038998e-01   8.70165751e-05   6.95044857e-05   5.01018929e-07]\n",
      " [  0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00]\n",
      " [  1.53977470e-03   9.99500185e-04   7.48507604e-04   3.11750030e-01]\n",
      " [  0.00000000e+00   4.33751774e-01   2.76153097e-03   3.45481079e-03]\n",
      " [  4.17703485e-01   3.16525055e-04   1.04114044e-03   0.00000000e+00]\n",
      " [  0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00]\n",
      " [  0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00]\n",
      " [  0.00000000e+00   1.12156334e-03   4.42061375e-01   0.00000000e+00]\n",
      " [  0.00000000e+00   6.68191121e-01   0.00000000e+00   0.00000000e+00]\n",
      " [  0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00]]\n"
     ]
    }
   ],
   "source": [
    "print(\"Final Q-Table Values\")\n",
    "print(Q)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (Left)\n",
      "SFFF\n",
      "FHFH\n",
      "F\u001b[41mF\u001b[0mFH\n",
      "HFFG\n"
     ]
    }
   ],
   "source": [
    "# print out the 4 x 4 grid and the current position of the agent\n",
    "env.render()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inline Question 1:\n",
    "In TODO(3), why not directly apply the Bellman equation for updating the Q value? (in this case lr = 1 and why?)\n",
    "\n",
    "**Your answer:** Because we don't know the real Q function and can only approach the value of it with an approximator, therefore take a step to the approximated direction in a small step is rational. Also if we totally rely on the previous Q-approximator, it'll accumulate the error in approximation and make the Q-approximator fail to converge. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inline Question 2:\n",
    "An optimal Q table will tell you the true expected discounted reward for any action given any state. If you find the maximum value of the learned table is not what you believe it should be, do you think it still make sense? Explain briefly.**\n",
    "\n",
    "**Your answer:** It makes sense. The actual state of agent doesn't onlytotally rely on its choice, but also some randomness. Under different environment it might learn some slightly different result, and that make Q table come to some optimal solution, which is not really applicable under all possibilies."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Part 2 - Q-Network Approach\n",
    "While it is easy to have a 16x4 table for a simple grid world, the number of possible states in any modern game or real-world environment is nearly infinitely larger. For most interesting problems, tables simply don’t work. We instead need some way to take a description of our state, and produce Q-values for actions without a table: that is where neural networks come in. By acting as a function approximator, we can take any number of possible states that can be represented as a vector and learn to map them to Q-values."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the case of the FrozenLake example, we will be using a one-layer network which takes the state encoded in a one-hot vector `(1x16)`, and produces a vector of 4 Q-values, one for each action. Such a simple network acts kind of like a glorified table, with the network weights serving as the old cells. The key difference is that we can easily expand the Tensorflow network with added layers, activation functions, and different input types, whereas all that is impossible with a regular table. The method of updating is a little different as well. Instead of directly updating our table, with a network we will be using backpropagation and a loss function. Our loss function will be sum-of-squares loss, where the difference between the current predicted Q-values, and the “target” value is computed and the gradients passed through the network. **In this case, our Q-target value for the chosen action is the equivalent to the Q-value computed in equation 1 above.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Implementing the network itself"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "env = gym.make('FrozenLake-v0')\n",
    "tf.reset_default_graph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#These lines establish the feed-forward part of the network used to choose actions\n",
    "inputs1 = tf.placeholder(shape=[1,16],dtype=tf.float32)\n",
    "W = tf.Variable(tf.random_uniform([16,4],0,0.01))\n",
    "Qout = tf.matmul(inputs1,W)\n",
    "predict = tf.argmax(Qout,1)\n",
    "\n",
    "#Below we obtain the loss by taking the sum of squares difference between the target and prediction Q values.\n",
    "nextQ = tf.placeholder(shape=[1,4],dtype=tf.float32)\n",
    "loss = tf.reduce_sum(tf.square(nextQ - Qout))\n",
    "trainer = tf.train.GradientDescentOptimizer(learning_rate=0.1)\n",
    "updateModel = trainer.minimize(loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training the network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Episode', 9, 'reward:', 0.0)\n",
      "('Episode', 19, 'reward:', 0.0)\n",
      "('Episode', 29, 'reward:', 0.0)\n",
      "('Episode', 39, 'reward:', 0.0)\n",
      "('Episode', 49, 'reward:', 0.0)\n",
      "('Episode', 59, 'reward:', 0.0)\n",
      "('Episode', 69, 'reward:', 0.10000000000000001)\n",
      "('Episode', 79, 'reward:', 0.0)\n",
      "('Episode', 89, 'reward:', 0.0)\n",
      "('Episode', 99, 'reward:', 0.0)\n",
      "('Episode', 109, 'reward:', 0.0)\n",
      "('Episode', 119, 'reward:', 0.0)\n",
      "('Episode', 129, 'reward:', 0.0)\n",
      "('Episode', 139, 'reward:', 0.20000000000000001)\n",
      "('Episode', 149, 'reward:', 0.0)\n",
      "('Episode', 159, 'reward:', 0.10000000000000001)\n",
      "('Episode', 169, 'reward:', 0.0)\n",
      "('Episode', 179, 'reward:', 0.0)\n",
      "('Episode', 189, 'reward:', 0.0)\n",
      "('Episode', 199, 'reward:', 0.0)\n",
      "('Episode', 209, 'reward:', 0.0)\n",
      "('Episode', 219, 'reward:', 0.0)\n",
      "('Episode', 229, 'reward:', 0.0)\n",
      "('Episode', 239, 'reward:', 0.0)\n",
      "('Episode', 249, 'reward:', 0.0)\n",
      "('Episode', 259, 'reward:', 0.10000000000000001)\n",
      "('Episode', 269, 'reward:', 0.0)\n",
      "('Episode', 279, 'reward:', 0.10000000000000001)\n",
      "('Episode', 289, 'reward:', 0.10000000000000001)\n",
      "('Episode', 299, 'reward:', 0.0)\n",
      "('Episode', 309, 'reward:', 0.10000000000000001)\n",
      "('Episode', 319, 'reward:', 0.10000000000000001)\n",
      "('Episode', 329, 'reward:', 0.0)\n",
      "('Episode', 339, 'reward:', 0.0)\n",
      "('Episode', 349, 'reward:', 0.20000000000000001)\n",
      "('Episode', 359, 'reward:', 0.10000000000000001)\n",
      "('Episode', 369, 'reward:', 0.0)\n",
      "('Episode', 379, 'reward:', 0.0)\n",
      "('Episode', 389, 'reward:', 0.10000000000000001)\n",
      "('Episode', 399, 'reward:', 0.0)\n",
      "('Episode', 409, 'reward:', 0.0)\n",
      "('Episode', 419, 'reward:', 0.0)\n",
      "('Episode', 429, 'reward:', 0.10000000000000001)\n",
      "('Episode', 439, 'reward:', 0.10000000000000001)\n",
      "('Episode', 449, 'reward:', 0.0)\n",
      "('Episode', 459, 'reward:', 0.10000000000000001)\n",
      "('Episode', 469, 'reward:', 0.5)\n",
      "('Episode', 479, 'reward:', 0.10000000000000001)\n",
      "('Episode', 489, 'reward:', 0.29999999999999999)\n",
      "('Episode', 499, 'reward:', 0.29999999999999999)\n",
      "('Episode', 509, 'reward:', 0.0)\n",
      "('Episode', 519, 'reward:', 0.10000000000000001)\n",
      "('Episode', 529, 'reward:', 0.20000000000000001)\n",
      "('Episode', 539, 'reward:', 0.29999999999999999)\n",
      "('Episode', 549, 'reward:', 0.10000000000000001)\n",
      "('Episode', 559, 'reward:', 0.10000000000000001)\n",
      "('Episode', 569, 'reward:', 0.29999999999999999)\n",
      "('Episode', 579, 'reward:', 0.40000000000000002)\n",
      "('Episode', 589, 'reward:', 0.29999999999999999)\n",
      "('Episode', 599, 'reward:', 0.10000000000000001)\n",
      "('Episode', 609, 'reward:', 0.40000000000000002)\n",
      "('Episode', 619, 'reward:', 0.40000000000000002)\n",
      "('Episode', 629, 'reward:', 0.20000000000000001)\n",
      "('Episode', 639, 'reward:', 0.10000000000000001)\n",
      "('Episode', 649, 'reward:', 0.20000000000000001)\n",
      "('Episode', 659, 'reward:', 0.0)\n",
      "('Episode', 669, 'reward:', 0.10000000000000001)\n",
      "('Episode', 679, 'reward:', 0.10000000000000001)\n",
      "('Episode', 689, 'reward:', 0.59999999999999998)\n",
      "('Episode', 699, 'reward:', 0.20000000000000001)\n",
      "('Episode', 709, 'reward:', 0.0)\n",
      "('Episode', 719, 'reward:', 0.20000000000000001)\n",
      "('Episode', 729, 'reward:', 0.29999999999999999)\n",
      "('Episode', 739, 'reward:', 0.20000000000000001)\n",
      "('Episode', 749, 'reward:', 0.40000000000000002)\n",
      "('Episode', 759, 'reward:', 0.80000000000000004)\n",
      "('Episode', 769, 'reward:', 0.69999999999999996)\n",
      "('Episode', 779, 'reward:', 0.29999999999999999)\n",
      "('Episode', 789, 'reward:', 0.40000000000000002)\n",
      "('Episode', 799, 'reward:', 0.29999999999999999)\n",
      "('Episode', 809, 'reward:', 0.59999999999999998)\n",
      "('Episode', 819, 'reward:', 0.29999999999999999)\n",
      "('Episode', 829, 'reward:', 0.5)\n",
      "('Episode', 839, 'reward:', 0.40000000000000002)\n",
      "('Episode', 849, 'reward:', 0.29999999999999999)\n",
      "('Episode', 859, 'reward:', 0.40000000000000002)\n",
      "('Episode', 869, 'reward:', 0.40000000000000002)\n",
      "('Episode', 879, 'reward:', 0.5)\n",
      "('Episode', 889, 'reward:', 0.40000000000000002)\n",
      "('Episode', 899, 'reward:', 0.5)\n",
      "('Episode', 909, 'reward:', 0.69999999999999996)\n",
      "('Episode', 919, 'reward:', 0.69999999999999996)\n",
      "('Episode', 929, 'reward:', 0.5)\n",
      "('Episode', 939, 'reward:', 0.69999999999999996)\n",
      "('Episode', 949, 'reward:', 0.5)\n",
      "('Episode', 959, 'reward:', 0.80000000000000004)\n",
      "('Episode', 969, 'reward:', 0.5)\n",
      "('Episode', 979, 'reward:', 0.5)\n",
      "('Episode', 989, 'reward:', 0.59999999999999998)\n",
      "('Episode', 999, 'reward:', 0.5)\n",
      "('Episode', 1009, 'reward:', 0.80000000000000004)\n",
      "('Episode', 1019, 'reward:', 0.80000000000000004)\n",
      "('Episode', 1029, 'reward:', 0.40000000000000002)\n",
      "('Episode', 1039, 'reward:', 0.69999999999999996)\n",
      "('Episode', 1049, 'reward:', 0.80000000000000004)\n",
      "('Episode', 1059, 'reward:', 0.5)\n",
      "('Episode', 1069, 'reward:', 0.69999999999999996)\n",
      "('Episode', 1079, 'reward:', 0.20000000000000001)\n",
      "('Episode', 1089, 'reward:', 0.59999999999999998)\n",
      "('Episode', 1099, 'reward:', 0.59999999999999998)\n",
      "('Episode', 1109, 'reward:', 0.40000000000000002)\n",
      "('Episode', 1119, 'reward:', 0.59999999999999998)\n",
      "('Episode', 1129, 'reward:', 0.29999999999999999)\n",
      "('Episode', 1139, 'reward:', 0.5)\n",
      "('Episode', 1149, 'reward:', 0.29999999999999999)\n",
      "('Episode', 1159, 'reward:', 0.40000000000000002)\n",
      "('Episode', 1169, 'reward:', 0.5)\n",
      "('Episode', 1179, 'reward:', 0.69999999999999996)\n",
      "('Episode', 1189, 'reward:', 0.69999999999999996)\n",
      "('Episode', 1199, 'reward:', 0.5)\n",
      "('Episode', 1209, 'reward:', 0.40000000000000002)\n",
      "('Episode', 1219, 'reward:', 0.80000000000000004)\n",
      "('Episode', 1229, 'reward:', 0.40000000000000002)\n",
      "('Episode', 1239, 'reward:', 0.59999999999999998)\n",
      "('Episode', 1249, 'reward:', 0.5)\n",
      "('Episode', 1259, 'reward:', 0.5)\n",
      "('Episode', 1269, 'reward:', 0.59999999999999998)\n",
      "('Episode', 1279, 'reward:', 0.40000000000000002)\n",
      "('Episode', 1289, 'reward:', 0.59999999999999998)\n",
      "('Episode', 1299, 'reward:', 0.59999999999999998)\n",
      "('Episode', 1309, 'reward:', 0.69999999999999996)\n",
      "('Episode', 1319, 'reward:', 0.59999999999999998)\n",
      "('Episode', 1329, 'reward:', 0.69999999999999996)\n",
      "('Episode', 1339, 'reward:', 0.5)\n",
      "('Episode', 1349, 'reward:', 0.59999999999999998)\n",
      "('Episode', 1359, 'reward:', 0.69999999999999996)\n",
      "('Episode', 1369, 'reward:', 0.69999999999999996)\n",
      "('Episode', 1379, 'reward:', 0.5)\n",
      "('Episode', 1389, 'reward:', 0.5)\n",
      "('Episode', 1399, 'reward:', 0.59999999999999998)\n",
      "('Episode', 1409, 'reward:', 0.59999999999999998)\n",
      "('Episode', 1419, 'reward:', 0.69999999999999996)\n",
      "('Episode', 1429, 'reward:', 0.69999999999999996)\n",
      "('Episode', 1439, 'reward:', 0.59999999999999998)\n",
      "('Episode', 1449, 'reward:', 0.5)\n",
      "('Episode', 1459, 'reward:', 0.59999999999999998)\n",
      "('Episode', 1469, 'reward:', 0.5)\n",
      "('Episode', 1479, 'reward:', 0.80000000000000004)\n",
      "('Episode', 1489, 'reward:', 0.40000000000000002)\n",
      "('Episode', 1499, 'reward:', 0.59999999999999998)\n",
      "('Episode', 1509, 'reward:', 0.5)\n",
      "('Episode', 1519, 'reward:', 0.80000000000000004)\n",
      "('Episode', 1529, 'reward:', 0.29999999999999999)\n",
      "('Episode', 1539, 'reward:', 0.59999999999999998)\n",
      "('Episode', 1549, 'reward:', 0.40000000000000002)\n",
      "('Episode', 1559, 'reward:', 0.40000000000000002)\n",
      "('Episode', 1569, 'reward:', 0.59999999999999998)\n",
      "('Episode', 1579, 'reward:', 0.40000000000000002)\n",
      "('Episode', 1589, 'reward:', 0.80000000000000004)\n",
      "('Episode', 1599, 'reward:', 0.80000000000000004)\n",
      "('Episode', 1609, 'reward:', 0.69999999999999996)\n",
      "('Episode', 1619, 'reward:', 0.80000000000000004)\n",
      "('Episode', 1629, 'reward:', 0.59999999999999998)\n",
      "('Episode', 1639, 'reward:', 0.5)\n",
      "('Episode', 1649, 'reward:', 0.40000000000000002)\n",
      "('Episode', 1659, 'reward:', 0.59999999999999998)\n",
      "('Episode', 1669, 'reward:', 0.5)\n",
      "('Episode', 1679, 'reward:', 0.29999999999999999)\n",
      "('Episode', 1689, 'reward:', 0.80000000000000004)\n",
      "('Episode', 1699, 'reward:', 0.59999999999999998)\n",
      "('Episode', 1709, 'reward:', 0.5)\n",
      "('Episode', 1719, 'reward:', 0.5)\n",
      "('Episode', 1729, 'reward:', 0.69999999999999996)\n",
      "('Episode', 1739, 'reward:', 0.29999999999999999)\n",
      "('Episode', 1749, 'reward:', 0.80000000000000004)\n",
      "('Episode', 1759, 'reward:', 0.59999999999999998)\n",
      "('Episode', 1769, 'reward:', 0.59999999999999998)\n",
      "('Episode', 1779, 'reward:', 0.40000000000000002)\n",
      "('Episode', 1789, 'reward:', 0.20000000000000001)\n",
      "('Episode', 1799, 'reward:', 0.40000000000000002)\n",
      "('Episode', 1809, 'reward:', 0.69999999999999996)\n",
      "('Episode', 1819, 'reward:', 0.5)\n",
      "('Episode', 1829, 'reward:', 0.69999999999999996)\n",
      "('Episode', 1839, 'reward:', 0.5)\n",
      "('Episode', 1849, 'reward:', 0.90000000000000002)\n",
      "('Episode', 1859, 'reward:', 0.69999999999999996)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Episode', 1869, 'reward:', 0.90000000000000002)\n",
      "('Episode', 1879, 'reward:', 0.80000000000000004)\n",
      "('Episode', 1889, 'reward:', 0.59999999999999998)\n",
      "('Episode', 1899, 'reward:', 0.59999999999999998)\n",
      "('Episode', 1909, 'reward:', 0.69999999999999996)\n",
      "('Episode', 1919, 'reward:', 0.80000000000000004)\n",
      "('Episode', 1929, 'reward:', 0.59999999999999998)\n",
      "('Episode', 1939, 'reward:', 0.40000000000000002)\n",
      "('Episode', 1949, 'reward:', 0.5)\n",
      "('Episode', 1959, 'reward:', 0.5)\n",
      "('Episode', 1969, 'reward:', 0.59999999999999998)\n",
      "('Episode', 1979, 'reward:', 0.59999999999999998)\n",
      "('Episode', 1989, 'reward:', 0.59999999999999998)\n",
      "('Episode', 1999, 'reward:', 0.59999999999999998)\n",
      "Percent of succesful episodes: 0.393%\n"
     ]
    }
   ],
   "source": [
    "init = tf.global_variables_initializer()\n",
    "\n",
    "# Set learning parameters\n",
    "#discounted factor\n",
    "y = .99\n",
    "#chance of random action\n",
    "e = 0.1\n",
    "num_episodes = 2000\n",
    "#create lists to contain total rewards and steps per episode\n",
    "jList = []\n",
    "rList = []\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "    for i in range(num_episodes):\n",
    "        #Reset environment and get first new observation\n",
    "        s = env.reset()\n",
    "        #Total reward in one episode\n",
    "        rAll = 0\n",
    "        d = False\n",
    "        j = 0\n",
    "        #The Q-Network\n",
    "        while j < 99:\n",
    "            j+=1\n",
    "            \n",
    "            ###############################################################################\n",
    "            # TODO: Implement the Q-network approach.                                     #\n",
    "            # You will need to do the following:                                          #\n",
    "            # (1) Choose an action by greedily (with e chance of random action, e=0.1)    # \n",
    "            #     from the Q-network                                                      #\n",
    "            # (2) Get new state s1, reward r and done d from environment                  #\n",
    "            # (3) Obtain the Q' values by feeding the new state through our network       # \n",
    "            # (4) Obtain maxQ' and set our target value for chosen action.                #\n",
    "            # (5) Train our network using target and predicted Q values                   #\n",
    "            # (6) Cumulate the total reward rAll                                          #\n",
    "            # (7) Update observation s                                                    #\n",
    "            # Note: In (1) we need to feed a one-hot vector encoding the state space to   # \n",
    "            #       our network. The environment represents the position in the grid-     #\n",
    "            #       world as a number between 0 and 15, e.g. if s=11, the one-hot vector  #\n",
    "            #       (here is inputs1) should be                                           #\n",
    "            #       [[ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  0.]]   #\n",
    "            ###############################################################################\n",
    "            s_one_hot = np.zeros([1, env.observation_space.n])\n",
    "            s_one_hot[0, s] = 1.\n",
    "            a, oQ = sess.run([predict, Qout], feed_dict={inputs1: s_one_hot})\n",
    "            a = a[0]\n",
    "            if np.random.rand() < e:\n",
    "                a = env.action_space.sample()\n",
    "            s1, r, d, _ = env.step(a)\n",
    "            s1_one_hot = np.zeros([1, env.observation_space.n])\n",
    "            s1_one_hot[0, s1] = 1.\n",
    "            Q_s1 = sess.run(Qout, feed_dict={inputs1: s1_one_hot})[0]\n",
    "            max_Q_s1 = np.max(Q_s1)\n",
    "            tQ_one_hot = oQ\n",
    "            tQ_one_hot[0, a] = r + y * max_Q_s1\n",
    "            sess.run(updateModel, feed_dict={inputs1: s_one_hot, nextQ: tQ_one_hot})\n",
    "            rAll += r\n",
    "            s = s1\n",
    "            ##############################################################################\n",
    "            #                             END OF YOUR CODE                               #\n",
    "            ##############################################################################\n",
    "            \n",
    "            if d == True:\n",
    "                #Reduce chance of random action as we train the model.\n",
    "                e = 1./((i/50) + 10)\n",
    "                break\n",
    "        jList.append(j)\n",
    "        rList.append(rAll)\n",
    "        if len(rList) % 10 == 0:\n",
    "            print(\"Episode\",i,\"reward:\",np.mean(rList[-10:]))\n",
    "print(\"Percent of succesful episodes: \" + str(sum(rList)/num_episodes) + \"%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Some statistics on network performance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that the network beings to consistly reach the goal around the 750 episode mark."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7faec47ebc50>]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXcAAAD8CAYAAACMwORRAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n8KwpnLD7AAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7faec6ec2ad0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(rList)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It also begins to progress through the environment for longer than chance around the 750 mark as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7faec4700f10>]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXoAAAD8CAYAAAB5Pm/hAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7faec669bc90>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(jList)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "While the network learns to solve the FrozenLake problem, it turns out it doesn’t do so quite as efficiently as the Q-Table. While neural networks allow for greater flexibility, they do so at the cost of stability when it comes to Q-Learning. There are a number of possible extensions to our simple Q-Network which allow for greater performance and more robust learning. we will be exploring those additions in Exercise 2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
